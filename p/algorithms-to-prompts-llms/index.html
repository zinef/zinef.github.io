<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="A deep dive into why algorithms were formalized to escape natural language ambiguity, and how LLMs bring natural language back as an interface for problem solving."><title>From Algorithms to Prompts: Did We Just Loop Back or Level Up?</title><link rel=canonical href=https://zinef.github.io/p/algorithms-to-prompts-llms/><link rel=stylesheet href=/scss/style.min.946cca6c6259ef94ac55abfae7c7bf3291ea3ed5eea17ef77500b257217c6710.css><meta property='og:title' content="From Algorithms to Prompts: Did We Just Loop Back or Level Up?"><meta property='og:description' content="A deep dive into why algorithms were formalized to escape natural language ambiguity, and how LLMs bring natural language back as an interface for problem solving."><meta property='og:url' content='https://zinef.github.io/p/algorithms-to-prompts-llms/'><meta property='og:site_name' content="Zine-eddine's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Algorithms'><meta property='article:tag' content='Turing'><meta property='article:tag' content='Church'><meta property='article:tag' content='Computability'><meta property='article:tag' content='Formalism'><meta property='article:tag' content='Natural Language Interfaces'><meta property='article:tag' content='Large Language Models'><meta property='article:tag' content='Agents'><meta property='article:tag' content='Problem Solving'><meta property='article:tag' content='Programming Abstractions'><meta property='article:published_time' content='2025-08-19T00:00:00+00:00'><meta property='article:modified_time' content='2025-08-19T00:00:00+00:00'><meta property='og:image' content='https://zinef.github.io/p/algorithms-to-prompts-llms/turing-m.jpeg'><meta name=twitter:title content="From Algorithms to Prompts: Did We Just Loop Back or Level Up?"><meta name=twitter:description content="A deep dive into why algorithms were formalized to escape natural language ambiguity, and how LLMs bring natural language back as an interface for problem solving."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://zinef.github.io/p/algorithms-to-prompts-llms/turing-m.jpeg'><link rel="shortcut icon" href=/Mugiwara.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-NZTWCSFPM5"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NZTWCSFPM5")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"dark")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_b6b517251c5ae6bb.jpg width=300 height=299 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>üç•</span></figure><div class=site-meta><h1 class=site-name><a href=/>Zine-eddine's Blog</a></h1><h2 class=site-description>Data Scientist | CS Engineer</h2></div></header><ol class=menu-social><li><a href=https://github.com/zinef target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/zinef/ target=_blank title=LinkedIn rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-linkedin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 10-4 0"/><path d="M3 7a4 4 0 014-4h10a4 4 0 014 4v10a4 4 0 01-4 4H7a4 4 0 01-4-4z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#why-formalize-algorithms-in-the-first-place->Why formalize algorithms in the first place ?</a></li><li><a href=#so-why-are-we-back-to-natural-language-now>So why are we ‚Äúback‚Äù to natural language now?</a></li><li><a href=#are-we-undoing-the-original-reasons-for-formalism>Are we undoing the original reasons for formalism?</a></li><li><a href=#when-is-natural-language-a-good-programming-layer>When is natural language a good ‚Äúprogramming layer‚Äù?</a></li><li><a href=#llms-reuse-existing-knowledge-prompts-just-query-it>LLMs reuse existing knowledge, prompts just query it</a></li><li><a href=#but-didnt-people-try-english-like-programming-before>But didn‚Äôt people try ‚ÄúEnglish-like programming‚Äù before?</a></li><li><a href=#a-sober-take-is-this-a-step-up>A sober take: is this a step up?</a></li><li><a href=#further-reading--references>Further reading & references</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/algorithms-to-prompts-llms/><img src=/p/algorithms-to-prompts-llms/turing-m_hu_4c416b6abc235788.jpeg srcset="/p/algorithms-to-prompts-llms/turing-m_hu_4c416b6abc235788.jpeg 800w, /p/algorithms-to-prompts-llms/turing-m_hu_173c5f01ebc08fb.jpeg 1600w" width=800 height=533 loading=lazy alt="Featured image of post From Algorithms to Prompts: Did We Just Loop Back or Level Up?"></a></div><div class=article-details><header class=article-category><a href=/categories/artificial-intelligence/>Artificial Intelligence
</a><a href=/categories/computer-science/>Computer Science
</a><a href=/categories/history-of-computing/>History of Computing</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/algorithms-to-prompts-llms/>From Algorithms to Prompts: Did We Just Loop Back or Level Up?</a></h2><h3 class=article-subtitle>A deep dive into why algorithms were formalized to escape natural language ambiguity, and how LLMs bring natural language back as an interface for problem solving.</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Aug 19, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>5 minute read</time></div></footer></div></header><section class=article-content><p>A century ago we invented <em>formal</em> ways to describe computations precisely because everyday language was too squishy. Now we‚Äôre steering powerful systems with‚Ä¶ everyday language. Is that progress or a regression?</p><p>Short answer: it‚Äôs a step sideways and up. We didn‚Äôt abandon formalism, we pushed it down a layer. Natural language is becoming the interface, while the machinery underneath is getting more formal (APIs, schemas, tools, verifiers). Below I‚Äôll unpack why the algorithmic formalists did what they did, how LLMs change the surface of programming, and when ‚ÄúEnglish as glue‚Äù is a good idea or a trap.</p><h2 id=why-formalize-algorithms-in-the-first-place->Why formalize algorithms in the first place ?</h2><p>Early 20th-century logicians tried to pin down what it means to compute at all. David Hilbert‚Äôs program asked whether there was a mechanical procedure to decide the truth of any statement in first-order logic (the Entscheidungsproblem). Alonzo Church (lambda calculus) and Alan Turing (Turing machines) independently answered no, but their negative answers gave us something priceless: precise models of effective procedure, what we now call algorithms. Their work, together with Post and Kleene, forms the backbone of the Church - Turing thesis and computability theory.</p><p>From there, computer science doubled down on precision inside programming, not just in computability theory:</p><ul><li><strong>Syntax</strong> got formal grammars (e.g., Backus‚ÄìNaur Form) to define languages unambiguously, famously in the ALGOL 60 report.</li><li><strong>Semantics and correctness</strong> got axioms and proofs (e.g., Hoare logic), and structured programming discouraged ambiguous control flow.</li></ul><p>The point was never to avoid natural language in discourse, but to ensure that what the <em>machine</em> sees is crisp, verifiable, and composable.</p><h2 id=so-why-are-we-back-to-natural-language-now>So why are we ‚Äúback‚Äù to natural language now?</h2><p>Because LLMs made natural language an effective <strong>specification medium</strong> for many tasks. A good prompt can compress years of prior work : data, code, papers ‚Ä¶ into a short instruction that selects and adapts knowledge. But crucially, recent LLM apps don‚Äôt stop at plain text:</p><ul><li><strong>Function/Tool calling</strong> turns a sentence into a typed API call with guaranteed structure. What the user says is fuzzy, what the system executes is precise.</li><li><strong>Agents + tools</strong> (search, code execution, calculators, retrievers) let models plan in language but act through formal interfaces.</li><li><strong>Structured outputs</strong> (JSON Schema) and <strong>constrained decoding</strong> force the model to emit data that matches a schema exactly, bridging natural prompts with machine-checkable results.</li></ul><p>In other words, we use natural language for <strong>intent capture</strong> and <strong>explanation</strong>, then immediately re-enter formal territory for <strong>execution</strong> and <strong>interoperability</strong>.</p><h2 id=are-we-undoing-the-original-reasons-for-formalism>Are we undoing the original reasons for formalism?</h2><p>No. We‚Äôre relocating formalism to the seams where it matters.</p><ul><li><strong>Ambiguity control</strong> moved from the user‚Äôs prompt to the <strong>contracts at the boundary</strong> (schemas, types, tools). With structured outputs and grammar-constrained decoding, you can make the generator respect your formal spec while still letting users speak freely.</li><li><strong>Verification</strong> is increasingly externalized: the model proposes, specialized solvers/checkers verify. This reflects a broader trend: treat the LLM as a parser/planner and let formal tools enforce correctness downstream.</li><li><strong>Proven limits</strong> still apply. Church-Turing didn‚Äôt go away, undecidability and incompleteness still constrain what any program or model can guarantee. The practical response is to bound the problem and add safeguards, not to hope that prose resolves impossibility.</li></ul><p>Think of LLMs as stochastic compilers <strong>from intent to actions</strong>. We‚Äôre not programming in English, we‚Äôre <strong>using English to drive formal systems</strong>.</p><h2 id=when-is-natural-language-a-good-programming-layer>When is natural language a good ‚Äúprogramming layer‚Äù?</h2><p><strong>Great for:</strong></p><ul><li><strong>Exploration & orchestration.</strong> ‚ÄúSummarize these docs, extract entities, then call the CRM API.‚Äù The natural language plan can be translated to tool calls with structured outputs so the rest of your stack stays typed.</li><li><strong>End-user customization.</strong> Users don‚Äôt want DSLs, they want results. NL prompts make power accessible, while your app constrains what can actually happen via tools and schemas.</li></ul><p><strong>Risky for:</strong></p><ul><li><strong>High-assurance logic.</strong> Dijkstra warned in 1978 against ‚Äúnatural language programming‚Äù because ambiguity clashes with the precision that programs require. The warning is still relevant unless you couple NL with formal constraints and verification.</li></ul><p>A pragmatic pattern is: <strong>Prompt ‚Üí Plan ‚Üí Structured Calls ‚Üí Verify ‚Üí Persist</strong>. The prompt is the human-friendly layer, everything after is formal and testable.</p><h2 id=llms-reuse-existing-knowledge-prompts-just-query-it>LLMs reuse existing knowledge, prompts just query it</h2><p>LLMs are trained on existing artifacts. At inference time they compose and contextualize that knowledge. Tool use and retrieval make this even clearer: the model plans in language but leans on external knowledge bases or APIs for facts and effects. Recent surveys of LLM-based agents document this emerging architecture, language for reasoning and coordination, tools for ground truth and action.</p><h2 id=but-didnt-people-try-english-like-programming-before>But didn‚Äôt people try ‚ÄúEnglish-like programming‚Äù before?</h2><p>Yes, COBOL‚Äôs Englishy syntax, HyperTalk, Inform 7, and decades of ‚Äúnatural language programming‚Äù experiments. The enduring critique, again from Dijkstra, is that surface readability doesn‚Äôt buy you <strong>semantic guarantees</strong>. What‚Äôs new now isn‚Äôt Englishy syntax, it‚Äôs <strong>learning-based intent capture + formal execution layers</strong>. The shift is closer to Andrej Karpathy‚Äôs ‚ÄúSoftware 2.0‚Äù idea, specifying behavior via data and learned models instead of only handwritten rules, now extended with a natural language interface on top.</p><h2 id=a-sober-take-is-this-a-step-up>A sober take: is this a step up?</h2><p>Yes, with guardrails. We improved the human-computer interface without discarding the computer‚Äôs need for formality. The socio-technical win is accessibility and speed, the technical debt is that ambiguity and hallucination creep back in unless you constrain, ground, and verify. The state of the art is actively addressing this with structured outputs, grammar-constrained decoding, and agent frameworks that keep LLMs honest by delegating to formal tools.</p><h2 id=further-reading--references>Further reading & references</h2><ul><li><p><strong>Why formalize algorithms / historical roots.</strong>
Stanford Encyclopedia entries on the Church-Turing Thesis and Computability, Turing (1936) and Church (1936) on the Entscheidungsproblem. <a class=link href=https://plato.stanford.edu/entries/church-turing/ target=_blank rel=noopener>plato.stanford.edu</a>, <a class=link href=https://dl.acm.org/doi/10.1145/360303.360308 target=_blank rel=noopener>dl.acm.org</a></p></li><li><p><strong>Language design and correctness.</strong>
ALGOL 60 report (BNF for syntax), Hoare‚Äôs ‚ÄúAn Axiomatic Basis for Computer Programming‚Äù, Dijkstra‚Äôs ‚ÄúGo To Statement Considered Harmful.‚Äù <a class=link href=https://www.masswerk.at/algol60/report.htm target=_blank rel=noopener>mass:werk ‚Äì media environments</a>,<a class=link href=https://eli-project.sourceforge.net/a60_html/a60.html target=_blank rel=noopener>eli-project.sourceforge.net</a>, <a class=link href=https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf target=_blank rel=noopener>homepages.cwi.nl</a></p></li><li><p><strong>Natural language programming debate.</strong>
Dijkstra‚Äôs <em>On the foolishness of ‚Äúnatural language programming‚Äù</em> (1978/79), The New Yorker‚Äôs ‚ÄúWhat if natural language replaced programming?‚Äù for a modern cultural view. <a class=link href=https://www.cs.utexas.edu/~EWD/ewd06xx/EWD667.PDF target=_blank rel=noopener>cs.utexas.edu</a></p></li><li><p><strong>LLMs as planners with tools.</strong>
ReAct (reasoning+acting) and Toolformer (teaching models to use tools), surveys of LLM-based agents. <a class=link href=https://arxiv.org/pdf/2210.03629 target=_blank rel=noopener>arXiv</a>, <a class=link href=https://openai.com/index/function-calling-and-other-api-updates/ target=_blank rel=noopener>openai.com</a></p></li><li><p><strong>Bridging NL to formal outputs.</strong>
OpenAI structured outputs (JSON Schema adherence) and research on constrained/grammar-guided decoding. <a class=link href=https://openai.com/index/introducing-structured-outputs-in-the-api/ target=_blank rel=noopener>openai.com</a>, <a class=link href=https://arxiv.org/html/2403.06988v1 target=_blank rel=noopener>arXiv</a>, <a class=link href=https://aclanthology.org/2025.acl-industry.34.pdf target=_blank rel=noopener>aclanthology.org</a></p></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/algorithms/>Algorithms</a>
<a href=/tags/turing/>Turing</a>
<a href=/tags/church/>Church</a>
<a href=/tags/computability/>Computability</a>
<a href=/tags/formalism/>Formalism</a>
<a href=/tags/natural-language-interfaces/>Natural Language Interfaces</a>
<a href=/tags/large-language-models/>Large Language Models</a>
<a href=/tags/agents/>Agents</a>
<a href=/tags/problem-solving/>Problem Solving</a>
<a href=/tags/programming-abstractions/>Programming Abstractions</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/llamaindex-rag-agents-javascript/><div class=article-image><img src=/p/llamaindex-rag-agents-javascript/llamaindex_js.c630bd4c6e4643610688751c9de00c69_hu_e18cd49f4a8bd81e.png width=250 height=150 loading=lazy alt="Featured image of post Building RAG and AI Agents using JavaScript: A Practical Guide with LlamaIndex.ts" data-key=llamaindex-rag-agents-javascript data-hash="md5-xjC9TG5GQ2EGiHUcneAMaQ=="></div><div class=article-details><h2 class=article-title>Building RAG and AI Agents using JavaScript: A Practical Guide with LlamaIndex.ts</h2></div></a></article><article class=has-image><a href=/p/openai-gpt-oss-models/><div class=article-image><img src=/p/openai-gpt-oss-models/open_ai.9b710bc2c78c6de107bade3339a4aa64_hu_ed4ed4db7ee4ac88.jpg width=250 height=150 loading=lazy alt="Featured image of post OpenAI Goes Open Source: Introducing GPT-OSS Models" data-key=openai-gpt-oss-models data-hash="md5-m3ELwseMbeEHut4zOaSqZA=="></div><div class=article-details><h2 class=article-title>OpenAI Goes Open Source: Introducing GPT-OSS Models</h2></div></a></article><article class=has-image><a href=/p/blender-mcp/><div class=article-image><img src=/p/blender-mcp/blender_mcp_cover.973af8610e4e049e417afe0132ce7972_hu_253eea1f9d0e737a.jpg width=250 height=150 loading=lazy alt="Featured image of post AI-Assisted 3D Design: Exploring Blender-MCP" data-key=blender-mcp data-hash="md5-lzr4YQ5OBJ5Bev4BMs55cg=="></div><div class=article-details><h2 class=article-title>AI-Assisted 3D Design: Exploring Blender-MCP</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//zinef.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 Zine-eddine's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>