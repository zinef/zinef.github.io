<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Leveraging deep learning to transform high-resolution medical images into actionable insights for brain tumor detection."><title>How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide</title><link rel=canonical href=https://zinef.github.io/p/lmianalysis/><link rel=stylesheet href=/scss/style.min.946cca6c6259ef94ac55abfae7c7bf3291ea3ed5eea17ef77500b257217c6710.css><meta property='og:title' content="How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide"><meta property='og:description' content="Leveraging deep learning to transform high-resolution medical images into actionable insights for brain tumor detection."><meta property='og:url' content='https://zinef.github.io/p/lmianalysis/'><meta property='og:site_name' content="Zine-eddine's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='Bioinformatics'><meta property='article:tag' content='Image Processing'><meta property='article:tag' content='Python'><meta property='article:tag' content='Classification'><meta property='article:published_time' content='2024-02-17T00:00:00+00:00'><meta property='article:modified_time' content='2024-02-17T00:00:00+00:00'><meta property='og:image' content='https://zinef.github.io/p/lmianalysis/biospecimen-whole-slide-image-1.png'><meta name=twitter:title content="How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide"><meta name=twitter:description content="Leveraging deep learning to transform high-resolution medical images into actionable insights for brain tumor detection."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://zinef.github.io/p/lmianalysis/biospecimen-whole-slide-image-1.png'><link rel="shortcut icon" href=/Mugiwara.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-NZTWCSFPM5"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NZTWCSFPM5")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"dark")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_b6b517251c5ae6bb.jpg width=300 height=299 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>üç•</span></figure><div class=site-meta><h1 class=site-name><a href=/>Zine-eddine's Blog</a></h1><h2 class=site-description>Data Scientist | CS Engineer</h2></div></header><ol class=menu-social><li><a href=https://github.com/zinef target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/zinef/ target=_blank title=LinkedIn rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-brand-linkedin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 10-4 0"/><path d="M3 7a4 4 0 014-4h10a4 4 0 014 4v10a4 4 0 01-4 4H7a4 4 0 01-4-4z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a></li><li><a href=#the-challenge-of-large-scale-medical-image-analysis>The Challenge of Large-Scale Medical Image Analysis</a><ol><li><a href=#key-challenges>Key Challenges</a></li></ol></li><li><a href=#the-solution-transforming-images-into-embeddings>The Solution: Transforming Images into Embeddings</a><ol><li><a href=#deep-attention-multiple-instance-survival-learning-deepattnmisl><strong>Deep Attention Multiple-Instance Survival Learning (DeepAttnMISL)</strong></a></li><li><a href=#vision-transformers-vits><strong>Vision Transformers (ViTs)</strong></a></li></ol></li><li><a href=#key-takeaways>Key Takeaways</a><ol><li><a href=#the-importance-of-representation-learning><strong>The Importance of Representation Learning</strong></a></li><li><a href=#attention-mechanisms-enhance-interpretability><strong>Attention Mechanisms Enhance Interpretability</strong></a></li><li><a href=#pretrained-models-save-time--resources><strong>Pretrained Models Save Time & Resources</strong></a></li><li><a href=#computational-constraints-are-a-real-challenge><strong>Computational Constraints Are a Real Challenge</strong></a></li></ol></li><li><a href=#conclusion>Conclusion</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/lmianalysis/><img src=/p/lmianalysis/biospecimen-whole-slide-image-1_hu_af46f814363a439a.png srcset="/p/lmianalysis/biospecimen-whole-slide-image-1_hu_af46f814363a439a.png 800w, /p/lmianalysis/biospecimen-whole-slide-image-1_hu_95adad9fd92a91a3.png 1600w" width=800 height=450 loading=lazy alt="Featured image of post How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide"></a></div><div class=article-details><header class=article-category><a href=/categories/data-science/>Data Science
</a><a href=/categories/ai/>AI
</a><a href=/categories/biology/>Biology
</a><a href=/categories/vision/>VISION</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/lmianalysis/>How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide</a></h2><h3 class=article-subtitle>Leveraging deep learning to transform high-resolution medical images into actionable insights for brain tumor detection.</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Feb 17, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>4 minute read</time></div></footer></div></header><section class=article-content><h2 id=introduction>Introduction</h2><p>Brain tumors are among the most aggressive and lethal forms of cancer, and early detection is crucial for improving patient outcomes. However, analyzing medical images to diagnose and classify brain tumors presents several challenges due to the sheer size and complexity of whole-slide images (WSIs). In this article, I will share insights from my project, <em>Converting Large Medical Images to Embeddings for Training Classifier Models</em>, where I leveraged deep learning techniques to process high-resolution medical images efficiently. This is not just a technical breakdown but a real-world experience of tackling the problem, highlighting key lessons and takeaways.</p><h2 id=the-challenge-of-large-scale-medical-image-analysis>The Challenge of Large-Scale Medical Image Analysis</h2><p>Medical images, particularly WSIs, are massive, often exceeding 100,000 pixels in resolution. Traditional image classification methods struggle to process such data due to memory constraints and computational complexity. My goal was to convert these high-dimensional images into meaningful embeddings that could be used for training classifier models to predict immune invasion stages in glioblastoma‚Äîa highly aggressive brain tumor.</p><h3 id=key-challenges>Key Challenges</h3><ol><li><strong>Data Size & Complexity:</strong> WSIs are gigapixel images that require efficient handling and storage.</li><li><strong>Annotation Scarcity:</strong> Unlike natural images, medical images require expert annotations, which are often limited.</li><li><strong>Feature Extraction:</strong> Extracting meaningful representations from these images without losing critical information.</li><li><strong>Computational Constraints:</strong> Training deep learning models on such large images is resource-intensive.</li></ol><h2 id=the-solution-transforming-images-into-embeddings>The Solution: Transforming Images into Embeddings</h2><p>To address these challenges, I explored and adapted two state-of-the-art deep learning approaches:</p><h3 id=deep-attention-multiple-instance-survival-learning-deepattnmisl><strong>Deep Attention Multiple-Instance Survival Learning (DeepAttnMISL)</strong></h3><p>DeepAttnMISL is a multiple-instance learning (MIL) approach designed for survival prediction from WSIs. Instead of classifying entire images at once, it breaks them into smaller regions (instances) and learns representations using an attention-based mechanism. Key steps included:</p><ul><li><strong>Patch Extraction & Clustering:</strong> Extracting patches from WSIs and grouping them into phenotype clusters.</li><li><strong>Feature Extraction via CNNs:</strong> Using a pre-trained VGG model to generate feature embeddings for each patch.</li><li><strong>Attention-Based Pooling:</strong> Aggregating patch-level information using an attention-based MIL pooling layer to make patient-level predictions.</li><li><strong>Final Classification:</strong> Using the learned embeddings to train a classifier model to predict immune invasion stages (A, B, C, D).</li></ul><h3 id=vision-transformers-vits><strong>Vision Transformers (ViTs)</strong></h3><p>Inspired by their success in NLP, I also explored Vision Transformers (ViTs), which process images as sequences of patches rather than relying on convolutions. ViTs leverage self-attention mechanisms to capture long-range dependencies, making them particularly suited for analyzing complex medical images.</p><ul><li><strong>Patch Tokenization:</strong> Splitting the large image into smaller fixed-size patches.</li><li><strong>Embedding Generation:</strong> Encoding each patch into a vector representation.</li><li><strong>Self-Attention Mechanism:</strong> Learning relationships between different patches to detect patterns indicative of tumor presence.</li><li><strong>Classifier Training:</strong> Using the learned representations to train a predictive model.</li></ul><h2 id=key-takeaways>Key Takeaways</h2><h3 id=the-importance-of-representation-learning><strong>The Importance of Representation Learning</strong></h3><p>Converting images into embeddings significantly reduced the computational burden while preserving essential features. Choosing the right architecture for embedding extraction was crucial‚ÄîDeepAttnMISL provided structured phenotype-based representations, while ViTs captured global dependencies.</p><h3 id=attention-mechanisms-enhance-interpretability><strong>Attention Mechanisms Enhance Interpretability</strong></h3><p>Using attention-based pooling allowed us to identify the most critical regions of the WSIs, improving both accuracy and interpretability. This was particularly useful for medical experts who need to understand model predictions.</p><h3 id=pretrained-models-save-time--resources><strong>Pretrained Models Save Time & Resources</strong></h3><p>Instead of training deep networks from scratch, leveraging pretrained models (e.g., VGG, ResNet) for feature extraction proved highly effective. Fine-tuning these models with domain-specific data further improved performance.</p><h3 id=computational-constraints-are-a-real-challenge><strong>Computational Constraints Are a Real Challenge</strong></h3><p>Processing high-resolution WSIs required significant memory and GPU resources. Using techniques like patch extraction, dimensionality reduction, and efficient batching helped mitigate these challenges.</p><h2 id=conclusion>Conclusion</h2><p>Analyzing medical images for brain tumor detection is a complex but highly impactful challenge. By leveraging DeepAttnMISL and Vision Transformers, we can efficiently extract meaningful embeddings that improve classification accuracy while reducing computational costs. This project highlighted the power of attention mechanisms in deep learning and underscored the importance of adapting models to the unique constraints of medical imaging.</p><p>For those interested in deep learning applications in healthcare, this field offers vast opportunities to push the boundaries of AI-driven diagnostics. Whether you&rsquo;re a researcher, practitioner, or enthusiast, the key takeaway is clear‚Äîsmart representation learning is the future of medical image analysis.</p><hr><p><em>What are your thoughts on AI in medical imaging? Have you worked on similar projects? Let&rsquo;s discuss in the comments!</em></p></section><footer class=article-footer><section class=article-tags><a href=/tags/bioinformatics/>Bioinformatics</a>
<a href=/tags/image-processing/>Image Processing</a>
<a href=/tags/python/>Python</a>
<a href=/tags/classification/>Classification</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/multiomics/><div class=article-image><img src=/p/multiomics/dna-closely.1c450067a55ffe5ed61b9d0048fda150_hu_ea8ec74402cc84d8.jpg width=250 height=150 loading=lazy alt="Featured image of post How to Effectively Explore and Analyze Multi-Omics Data: Experience Report on Our Web Interface" data-key=multiomics data-hash="md5-HEUAZ6Vf/l7WG50ASP2hUA=="></div><div class=article-details><h2 class=article-title>How to Effectively Explore and Analyze Multi-Omics Data: Experience Report on Our Web Interface</h2></div></a></article><article class=has-image><a href=/p/genai_6_22/><div class=article-image><img src=/p/genai_6_22/cover.c514d916917173a48a42e0114b469961_hu_12cb662251854034.jpg width=250 height=150 loading=lazy alt="Featured image of post Unleash Limitless Possibilities: Harness the Power of Generative AI to Meet Market Demands and Delight Your Clients" data-key=GenAI_6_22 data-hash="md5-xRTZFpFxc6SKQuARS0aZYQ=="></div><div class=article-details><h2 class=article-title>Unleash Limitless Possibilities: Harness the Power of Generative AI to Meet Market Demands and Delight Your Clients</h2></div></a></article><article class=has-image><a href=/p/tensorstego/><div class=article-image><img src=/p/tensorstego/tensor_stego_cover.b7c5e0b096fce89a43a534d2bca01d91_hu_fbae5e385941991d.jpg width=250 height=150 loading=lazy alt="Featured image of post The Hidden Threat: Using Steganography to Hide Malicious Payloads in Deep Learning Models" data-key=tensorStego data-hash="md5-t8XgsJb86JpDpTTSvKAdkQ=="></div><div class=article-details><h2 class=article-title>The Hidden Threat: Using Steganography to Hide Malicious Payloads in Deep Learning Models</h2></div></a></article><article class=has-image><a href=/p/mlops_6_23/><div class=article-image><img src=/p/mlops_6_23/MLOps-DevOps.fa99a5f685ca76503b92c9bf51a8f709_hu_6b9ff7ab4ff12b5b.webp width=250 height=150 loading=lazy alt="Featured image of post MLOps: Introduction, Definitions and Best Practices" data-key=mlops_6_23 data-hash="md5-+pml9oXKdlA7ksm/Uaj3CQ=="></div><div class=article-details><h2 class=article-title>MLOps: Introduction, Definitions and Best Practices</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//zinef.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 Zine-eddine's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>