<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Zine-eddine's Blog</title><link>https://zinef.github.io/</link><description>Recent content on Zine-eddine's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 19 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://zinef.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Welcome to my Work Adventure</title><link>https://zinef.github.io/p/myworkadventure/</link><pubDate>Tue, 14 May 2024 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/myworkadventure/</guid><description>&lt;img src="https://zinef.github.io/p/myworkadventure/wa.png" alt="Featured image of post Welcome to my Work Adventure" />&lt;h2 id="-welcome-to-my-work-adventure">ðŸš€ Welcome to My Work Adventure!
&lt;/h2>&lt;p>Join me in a virtual workspace powered by WorkAdventure! Walk around, interact, and collaborate in a dynamic 2D environment. Whether you want to discuss data science, AI, or just say hi, step into my virtual office and let&amp;rsquo;s connect!&lt;/p>
&lt;p>ðŸ‘‰ &lt;a class="link" href="https://play.workadventu.re/_/pracyaq09ac/zinef.github.io/MyWA/map.tmj" target="_blank" rel="noopener"
>Enter My WorkAdventure&lt;/a>&lt;/p></description></item><item><title>From Algorithms to Prompts: Did We Just Loop Back or Level Up?</title><link>https://zinef.github.io/p/algorithms-to-prompts-llms/</link><pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/algorithms-to-prompts-llms/</guid><description>&lt;img src="https://zinef.github.io/p/algorithms-to-prompts-llms/turing-m.jpeg" alt="Featured image of post From Algorithms to Prompts: Did We Just Loop Back or Level Up?" />&lt;p>A century ago we invented &lt;em>formal&lt;/em> ways to describe computations precisely because everyday language was too squishy. Now weâ€™re steering powerful systems withâ€¦ everyday language. Is that progress or a regression?&lt;/p>
&lt;p>Short answer: itâ€™s a step sideways and up. We didnâ€™t abandon formalism, we pushed it down a layer. Natural language is becoming the interface, while the machinery underneath is getting more formal (APIs, schemas, tools, verifiers). Below Iâ€™ll unpack why the algorithmic formalists did what they did, how LLMs change the surface of programming, and when â€œEnglish as glueâ€ is a good idea or a trap.&lt;/p>
&lt;h2 id="why-formalize-algorithms-in-the-first-place-">Why formalize algorithms in the first place ?
&lt;/h2>&lt;p>Early 20th-century logicians tried to pin down what it means to compute at all. David Hilbertâ€™s program asked whether there was a mechanical procedure to decide the truth of any statement in first-order logic (the Entscheidungsproblem). Alonzo Church (lambda calculus) and Alan Turing (Turing machines) independently answered no, but their negative answers gave us something priceless: precise models of effective procedure, what we now call algorithms. Their work, together with Post and Kleene, forms the backbone of the Church - Turing thesis and computability theory.&lt;/p>
&lt;p>From there, computer science doubled down on precision inside programming, not just in computability theory:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Syntax&lt;/strong> got formal grammars (e.g., Backusâ€“Naur Form) to define languages unambiguously, famously in the ALGOL 60 report.&lt;/li>
&lt;li>&lt;strong>Semantics and correctness&lt;/strong> got axioms and proofs (e.g., Hoare logic), and structured programming discouraged ambiguous control flow.&lt;/li>
&lt;/ul>
&lt;p>The point was never to avoid natural language in discourse, but to ensure that what the &lt;em>machine&lt;/em> sees is crisp, verifiable, and composable.&lt;/p>
&lt;h2 id="so-why-are-we-back-to-natural-language-now">So why are we â€œbackâ€ to natural language now?
&lt;/h2>&lt;p>Because LLMs made natural language an effective &lt;strong>specification medium&lt;/strong> for many tasks. A good prompt can compress years of prior work : data, code, papers â€¦ into a short instruction that selects and adapts knowledge. But crucially, recent LLM apps donâ€™t stop at plain text:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Function/Tool calling&lt;/strong> turns a sentence into a typed API call with guaranteed structure. What the user says is fuzzy, what the system executes is precise.&lt;/li>
&lt;li>&lt;strong>Agents + tools&lt;/strong> (search, code execution, calculators, retrievers) let models plan in language but act through formal interfaces.&lt;/li>
&lt;li>&lt;strong>Structured outputs&lt;/strong> (JSON Schema) and &lt;strong>constrained decoding&lt;/strong> force the model to emit data that matches a schema exactly, bridging natural prompts with machine-checkable results.&lt;/li>
&lt;/ul>
&lt;p>In other words, we use natural language for &lt;strong>intent capture&lt;/strong> and &lt;strong>explanation&lt;/strong>, then immediately re-enter formal territory for &lt;strong>execution&lt;/strong> and &lt;strong>interoperability&lt;/strong>.&lt;/p>
&lt;h2 id="are-we-undoing-the-original-reasons-for-formalism">Are we undoing the original reasons for formalism?
&lt;/h2>&lt;p>No. Weâ€™re relocating formalism to the seams where it matters.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Ambiguity control&lt;/strong> moved from the userâ€™s prompt to the &lt;strong>contracts at the boundary&lt;/strong> (schemas, types, tools). With structured outputs and grammar-constrained decoding, you can make the generator respect your formal spec while still letting users speak freely.&lt;/li>
&lt;li>&lt;strong>Verification&lt;/strong> is increasingly externalized: the model proposes, specialized solvers/checkers verify. This reflects a broader trend: treat the LLM as a parser/planner and let formal tools enforce correctness downstream.&lt;/li>
&lt;li>&lt;strong>Proven limits&lt;/strong> still apply. Church-Turing didnâ€™t go away, undecidability and incompleteness still constrain what any program or model can guarantee. The practical response is to bound the problem and add safeguards, not to hope that prose resolves impossibility.&lt;/li>
&lt;/ul>
&lt;p>Think of LLMs as stochastic compilers &lt;strong>from intent to actions&lt;/strong>. Weâ€™re not programming in English, weâ€™re &lt;strong>using English to drive formal systems&lt;/strong>.&lt;/p>
&lt;h2 id="when-is-natural-language-a-good-programming-layer">When is natural language a good â€œprogramming layerâ€?
&lt;/h2>&lt;p>&lt;strong>Great for:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Exploration &amp;amp; orchestration.&lt;/strong> â€œSummarize these docs, extract entities, then call the CRM API.â€ The natural language plan can be translated to tool calls with structured outputs so the rest of your stack stays typed.&lt;/li>
&lt;li>&lt;strong>End-user customization.&lt;/strong> Users donâ€™t want DSLs, they want results. NL prompts make power accessible, while your app constrains what can actually happen via tools and schemas.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Risky for:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>High-assurance logic.&lt;/strong> Dijkstra warned in 1978 against â€œnatural language programmingâ€ because ambiguity clashes with the precision that programs require. The warning is still relevant unless you couple NL with formal constraints and verification.&lt;/li>
&lt;/ul>
&lt;p>A pragmatic pattern is: &lt;strong>Prompt â†’ Plan â†’ Structured Calls â†’ Verify â†’ Persist&lt;/strong>. The prompt is the human-friendly layer, everything after is formal and testable.&lt;/p>
&lt;h2 id="llms-reuse-existing-knowledge-prompts-just-query-it">LLMs reuse existing knowledge, prompts just query it
&lt;/h2>&lt;p>LLMs are trained on existing artifacts. At inference time they compose and contextualize that knowledge. Tool use and retrieval make this even clearer: the model plans in language but leans on external knowledge bases or APIs for facts and effects. Recent surveys of LLM-based agents document this emerging architecture, language for reasoning and coordination, tools for ground truth and action.&lt;/p>
&lt;h2 id="but-didnt-people-try-english-like-programming-before">But didnâ€™t people try â€œEnglish-like programmingâ€ before?
&lt;/h2>&lt;p>Yes, COBOLâ€™s Englishy syntax, HyperTalk, Inform 7, and decades of â€œnatural language programmingâ€ experiments. The enduring critique, again from Dijkstra, is that surface readability doesnâ€™t buy you &lt;strong>semantic guarantees&lt;/strong>. Whatâ€™s new now isnâ€™t Englishy syntax, itâ€™s &lt;strong>learning-based intent capture + formal execution layers&lt;/strong>. The shift is closer to Andrej Karpathyâ€™s â€œSoftware 2.0â€ idea, specifying behavior via data and learned models instead of only handwritten rules, now extended with a natural language interface on top.&lt;/p>
&lt;h2 id="a-sober-take-is-this-a-step-up">A sober take: is this a step up?
&lt;/h2>&lt;p>Yes, with guardrails. We improved the human-computer interface without discarding the computerâ€™s need for formality. The socio-technical win is accessibility and speed, the technical debt is that ambiguity and hallucination creep back in unless you constrain, ground, and verify. The state of the art is actively addressing this with structured outputs, grammar-constrained decoding, and agent frameworks that keep LLMs honest by delegating to formal tools.&lt;/p>
&lt;h2 id="further-reading--references">Further reading &amp;amp; references
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;strong>Why formalize algorithms / historical roots.&lt;/strong>
Stanford Encyclopedia entries on the Church-Turing Thesis and Computability, Turing (1936) and Church (1936) on the Entscheidungsproblem. &lt;a class="link" href="https://plato.stanford.edu/entries/church-turing/" target="_blank" rel="noopener"
>plato.stanford.edu&lt;/a>, &lt;a class="link" href="https://dl.acm.org/doi/10.1145/360303.360308" target="_blank" rel="noopener"
>dl.acm.org&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Language design and correctness.&lt;/strong>
ALGOL 60 report (BNF for syntax), Hoareâ€™s â€œAn Axiomatic Basis for Computer Programmingâ€, Dijkstraâ€™s â€œGo To Statement Considered Harmful.â€ &lt;a class="link" href="https://www.masswerk.at/algol60/report.htm" target="_blank" rel="noopener"
>mass:werk â€“ media environments&lt;/a>,&lt;a class="link" href="https://eli-project.sourceforge.net/a60_html/a60.html" target="_blank" rel="noopener"
>eli-project.sourceforge.net&lt;/a>, &lt;a class="link" href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf" target="_blank" rel="noopener"
>homepages.cwi.nl&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Natural language programming debate.&lt;/strong>
Dijkstraâ€™s &lt;em>On the foolishness of â€œnatural language programmingâ€&lt;/em> (1978/79), The New Yorkerâ€™s â€œWhat if natural language replaced programming?â€ for a modern cultural view. &lt;a class="link" href="https://www.cs.utexas.edu/~EWD/ewd06xx/EWD667.PDF" target="_blank" rel="noopener"
>cs.utexas.edu&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>LLMs as planners with tools.&lt;/strong>
ReAct (reasoning+acting) and Toolformer (teaching models to use tools), surveys of LLM-based agents. &lt;a class="link" href="https://arxiv.org/pdf/2210.03629" target="_blank" rel="noopener"
>arXiv&lt;/a>, &lt;a class="link" href="https://openai.com/index/function-calling-and-other-api-updates/" target="_blank" rel="noopener"
>openai.com&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Bridging NL to formal outputs.&lt;/strong>
OpenAI structured outputs (JSON Schema adherence) and research on constrained/grammar-guided decoding. &lt;a class="link" href="https://openai.com/index/introducing-structured-outputs-in-the-api/" target="_blank" rel="noopener"
>openai.com&lt;/a>, &lt;a class="link" href="https://arxiv.org/html/2403.06988v1" target="_blank" rel="noopener"
>arXiv&lt;/a>, &lt;a class="link" href="https://aclanthology.org/2025.acl-industry.34.pdf" target="_blank" rel="noopener"
>aclanthology.org&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Building RAG and AI Agents using JavaScript: A Practical Guide with LlamaIndex.ts</title><link>https://zinef.github.io/p/llamaindex-rag-agents-javascript/</link><pubDate>Sat, 16 Aug 2025 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/llamaindex-rag-agents-javascript/</guid><description>&lt;img src="https://zinef.github.io/p/llamaindex-rag-agents-javascript/llamaindex_js.png" alt="Featured image of post Building RAG and AI Agents using JavaScript: A Practical Guide with LlamaIndex.ts" />&lt;p>The JavaScript ecosystem has evolved far beyond web development, and the AI revolution is no exception. With the rise of powerful LLMs and the growing need for intelligent applications, JavaScript developers now have robust tools to build Retrieval-Augmented Generation (RAG) systems and AI agents directly in their preferred language.&lt;/p>
&lt;p>Today, libraries like LangChain.js and LlamaIndex.ts bring enterprise-grade AI capabilities to JavaScript, enabling developers to create sophisticated RAG systems and autonomous agents that can run in browsers, Node.js environments, or edge computing platforms.&lt;/p>
&lt;p>For this implementation, we&amp;rsquo;ll be using locally deployed language models through Ollama, specifically lightweight models like tinyllama, llama3.2:1b â€¦ which provide a good performance for RAG and agent applications while running entirely on local hardware.&lt;/p>
&lt;p>In this comprehensive guide, we&amp;rsquo;ll explore how to leverage LlamaIndex.ts to create both RAG systems and AI agents, complete with practical implementations and real-world use cases that demonstrate the framework&amp;rsquo;s capabilities.&lt;/p>
&lt;h2 id="why-javascript-for-ai-development">Why JavaScript for AI Development?
&lt;/h2>&lt;p>Before diving into implementation details, it&amp;rsquo;s worth understanding why JavaScript has become a compelling choice for AI development:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Universal Runtime&lt;/strong>: JavaScript runs everywhere - browsers, servers, mobile apps, and edge devices. This universality means your AI applications can be deployed across diverse environments without language barriers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Real-time Capabilities&lt;/strong>: JavaScript&amp;rsquo;s event-driven nature and WebSocket support make it ideal for building responsive AI applications that need to handle streaming responses and real-time interactions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ecosystem Maturity&lt;/strong>: With npm&amp;rsquo;s vast package ecosystem and mature tooling, JavaScript provides excellent developer experience and extensive third-party integrations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Performance&lt;/strong>: Modern JavaScript engines like V8 offer impressive performance, and tools like WebAssembly bridge the gap for computationally intensive tasks.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="why-llamaindexts-for-rag-and-agents">Why LlamaIndex.ts for RAG and Agents?
&lt;/h2>&lt;p>LlamaIndex.ts represents a paradigm shift for web developers entering the AI space. Unlike Python-centric alternatives, it integrates seamlessly with existing JavaScript infrastructures, enabling developers to build AI applications without context switching between languages.&lt;/p>
&lt;p>The framework offers several compelling advantages:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Native JavaScript Integration&lt;/strong>: Deploy RAG systems and agents directly within Node.js applications, Next.js projects, or even browser environments without complex language interoperability layers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Performance Optimization&lt;/strong>: Built with modern JavaScript practices, LlamaIndex.ts leverages async/await patterns and streaming capabilities for responsive AI applications.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ecosystem Compatibility&lt;/strong>: Integrates naturally with popular JavaScript libraries, databases, and web frameworks, reducing friction in existing development workflows.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Edge Computing Ready&lt;/strong>: The lightweight nature of JavaScript makes it ideal for edge deployments, bringing AI capabilities closer to users.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="understanding-rag-architecture">Understanding RAG Architecture
&lt;/h2>&lt;p>Retrieval-Augmented Generation combines the power of large language models with external knowledge sources. Instead of relying solely on pre-trained knowledge, RAG systems retrieve relevant information from custom datasets and use it to generate more accurate, contextually relevant responses.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/llamaindex-rag-agents-javascript/rag.png"
width="1342"
height="650"
srcset="https://zinef.github.io/p/llamaindex-rag-agents-javascript/rag_hu_c30913be13f80ade.png 480w, https://zinef.github.io/p/llamaindex-rag-agents-javascript/rag_hu_29fa24a09ce8a09d.png 1024w"
loading="lazy"
alt="source : https://docs.llamaindex.ai/en/stable/understanding/rag/"
class="gallery-image"
data-flex-grow="206"
data-flex-basis="495px"
>&lt;/p>
&lt;p>The typical RAG pipeline consists of four key stages:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Document Ingestion&lt;/strong>: Processing and preparing source documents&lt;/li>
&lt;li>&lt;strong>Embedding Generation&lt;/strong>: Converting text into vector representations&lt;/li>
&lt;li>&lt;strong>Vector Storage&lt;/strong>: Storing embeddings in a searchable format&lt;/li>
&lt;li>&lt;strong>Retrieval and Generation&lt;/strong>: Finding relevant context and generating responses&lt;/li>
&lt;/ol>
&lt;p>LlamaIndex.ts streamlines this entire pipeline while providing fine-grained control over each component.&lt;/p>
&lt;h2 id="prerequisites">Prerequisites
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;strong>Node.js&lt;/strong> â‰¥ 18 (â‰¥ 20 recommended) and &lt;strong>npm&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ollama&lt;/strong> running locally (&lt;code>ollama serve&lt;/code>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Local models already pulled, e.g.:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># choose a model you have locally (examples)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ollama pull tinyllama # or gpt-oss-20b, llama3.1:8b, mistral, etc.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ollama pull nomic-embed-text # embedding model
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>A new empty folder for each project (weâ€™ll keep &lt;strong>RAG&lt;/strong> and &lt;strong>Agent&lt;/strong> separate).&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>Note 1 :&lt;/em>&lt;/strong> &lt;em>Weâ€™ll use plain &lt;strong>JavaScript (ESM)&lt;/strong> to keep things frictionless. If you prefer TypeScript, just rename files to &lt;code>.ts&lt;/code> and add a &lt;code>tsconfig.json&lt;/code> , the imports stay the same.&lt;/em>&lt;/p>&lt;/blockquote>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>Note 2 :&lt;/em>&lt;/strong> &lt;em>The following code is intentionally kept simple and minimal so itâ€™s easy to follow in a blog format.&lt;/em>
&lt;em>In a real project, youâ€™d usually want to &lt;strong>refactor&lt;/strong> it into separate modules (for example, moving the agent or RAG logic into its own file and keeping the CLI entrypoint clean).&lt;/em>
&lt;em>This also makes it easier to add more functionality later (extra tools, different LLMs/embeddings, richer error handling, etc.). The nice thing is that the core logic stays the same. You can scale the structure as your project grows.&lt;/em>&lt;/p>&lt;/blockquote>
&lt;h2 id="minimal-local-rag">&lt;strong>Minimal Local RAG&lt;/strong>
&lt;/h2>&lt;h3 id="scaffold">Scaffold
&lt;/h3>&lt;p>Create a folder : &lt;code>rag-llamaindex-js/&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">rag-llamaindex-js/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> package.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> index.js
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> data/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> your-notes.md
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> another-file.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> storage/ # will be created automatically
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>package.json&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;local-rag-llamaindex&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;private&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;module&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;scripts&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;start&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;node index.js&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;clean&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;rimraf storage&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;dependencies&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;llamaindex&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;@llamaindex/ollama&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;@llamaindex/readers&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;devDependencies&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;rimraf&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>Install:&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">cd rag-llamaindex-js
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">npm i
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Put a couple of small &lt;code>.md&lt;/code> or &lt;code>.txt&lt;/code> files into &lt;code>./data&lt;/code> .&lt;/p>
&lt;h3 id="rag">RAG
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Imports
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">Settings&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">VectorStoreIndex&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">storageContextFromDefaults&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;llamaindex&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">SimpleDirectoryReader&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;@llamaindex/readers/directory&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">ollama&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">OllamaEmbedding&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;@llamaindex/ollama&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Configure local LLM + local embeddings
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">Settings&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">llm&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">ollama&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="nx">model&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">process&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">env&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">OLLAMA_LLM&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="s2">&amp;#34;tinyllama&amp;#34;&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">Settings&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">embedModel&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">OllamaEmbedding&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">model&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">process&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">env&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">OLLAMA_EMBED&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="s2">&amp;#34;nomic-embed-text&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">DATA_DIR&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./data&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">PERSIST_DIR&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;./storage&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="c1">// vector + docstore persisted locally
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// 1) Loading &amp;amp; ingestion
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">async&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="nx">loadDocuments&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">reader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">SimpleDirectoryReader&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">reader&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">loadData&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="nx">directoryPath&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">DATA_DIR&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// 2) Indexing &amp;amp; embedding + 3) Storing (persisted via storageContext)
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">async&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="nx">buildIndex&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">documents&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">storageContext&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">storageContextFromDefaults&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="nx">persistDir&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">PERSIST_DIR&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">VectorStoreIndex&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">fromDocuments&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">documents&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">storageContext&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// (Optional) If you want to reload later without re-embedding.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// import { VectorStoreIndex } from &amp;#34;llamaindex&amp;#34;;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// const storageContext = await storageContextFromDefaults({ persistDir: PERSIST_DIR });
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// const index = await VectorStoreIndex.init({ storageContext });
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// 4) Querying
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">async&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="nx">query&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">index&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">question&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">queryEngine&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">index&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">asQueryEngine&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="nx">similarityTopK&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="mi">3&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">res&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">queryEngine&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">query&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="nx">query&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">question&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">res&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Entrypoint
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">question&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">process&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">argv&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">slice&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="nx">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="s2">&amp;#34;What are the key ideas in these documents?&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">docs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">loadDocuments&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">index&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">buildIndex&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">docs&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">res&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">query&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">index&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">question&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;\nQ:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">question&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;\nAnswer:\n&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">res&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">response&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;\nSources:&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">s&lt;/span> &lt;span class="k">of&lt;/span> &lt;span class="nx">res&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">sourceNodes&lt;/span> &lt;span class="o">??&lt;/span> &lt;span class="p">[])&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;-&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">s&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">node&lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">metadata&lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">file_name&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="nx">s&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">id_&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="run-it">Run it
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># terminal 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ollama serve
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># terminal 2 (in rag-llamaindex-js/)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">node index.js &amp;#34;Summarize the main points across these docs.&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Youâ€™ll see an answer and a short list of source files like this.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/llamaindex-rag-agents-javascript/rag-res.png"
width="1409"
height="461"
srcset="https://zinef.github.io/p/llamaindex-rag-agents-javascript/rag-res_hu_a689e67d1ffc9871.png 480w, https://zinef.github.io/p/llamaindex-rag-agents-javascript/rag-res_hu_5682201724270bed.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="305"
data-flex-basis="733px"
>&lt;/p>
&lt;h2 id="minimal-local-agent">&lt;strong>Minimal Local Agent&lt;/strong>
&lt;/h2>&lt;h3 id="scaffold-1">Scaffold
&lt;/h3>&lt;p>Create a new folder : &lt;code>agent-llamaindex-js/&lt;/code> :&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">agent-llamaindex-js/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> package.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> index.js
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>package.json&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;name&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;local-agent-llamaindex&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;private&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;type&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;module&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;scripts&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;start&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;node index.js&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;dependencies&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;llamaindex&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;@llamaindex/ollama&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;@llamaindex/workflow&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;#34;zod&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;latest&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;strong>Install:&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="line">&lt;span class="cl">&lt;span class="err">cd&lt;/span> &lt;span class="err">agent-llamaindex-js&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">npm&lt;/span> &lt;span class="err">i&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="agent">Agent
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-js" data-lang="js">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Imports
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">Settings&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">tool&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;llamaindex&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">agent&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;@llamaindex/workflow&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">z&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;zod&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">ollama&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="nx">from&lt;/span> &lt;span class="s2">&amp;#34;@llamaindex/ollama&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// Local LLM via Ollama
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="nx">Settings&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">llm&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">ollama&lt;/span>&lt;span class="p">({&lt;/span> &lt;span class="nx">model&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">process&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">env&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">OLLAMA_LLM&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="s2">&amp;#34;llama3.2:1b&amp;#34;&lt;/span> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">// A strict calculator tool
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">addTool&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">tool&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">name&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;sumNumbers&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">description&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;Add two numbers and return the sum as a string.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">parameters&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">z&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">object&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">a&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">z&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">number&lt;/span>&lt;span class="p">().&lt;/span>&lt;span class="nx">describe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;First addend&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">b&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="nx">z&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">number&lt;/span>&lt;span class="p">().&lt;/span>&lt;span class="nx">describe&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Second addend&amp;#34;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">execute&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">({&lt;/span> &lt;span class="nx">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">b&lt;/span> &lt;span class="p">})&lt;/span> &lt;span class="p">=&amp;gt;&lt;/span> &lt;span class="sb">`&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nx">a&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nx">b&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="sb">`&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kr">async&lt;/span> &lt;span class="kd">function&lt;/span> &lt;span class="nx">main&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">myAgent&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">agent&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">systemPrompt&lt;/span>&lt;span class="o">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;You are a precise assistant. Use tools when helpful. After using tools, output only the final answer.&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">tools&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="nx">addTool&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="nx">userInput&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">process&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">argv&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">slice&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">).&lt;/span>&lt;span class="nx">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">||&lt;/span> &lt;span class="s2">&amp;#34;Add 101 and 303&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kr">const&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">data&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kr">await&lt;/span> &lt;span class="nx">myAgent&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">userInput&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;\nUser:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">userInput&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;\nAgent:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">data&lt;/span>&lt;span class="o">?&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">result&lt;/span> &lt;span class="o">??&lt;/span> &lt;span class="nb">String&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">data&lt;/span>&lt;span class="p">));&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">main&lt;/span>&lt;span class="p">().&lt;/span>&lt;span class="k">catch&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="nx">e&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">=&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">error&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">e&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">process&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">exit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>&lt;strong>&lt;em>Note :&lt;/em>&lt;/strong> &lt;em>Ensure you have a model that supports tool using, here weâ€™re using llama3.2:1b.&lt;/em>&lt;/p>&lt;/blockquote>
&lt;h3 id="run-it-1">Run it
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># terminal 1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ollama&lt;/span> &lt;span class="n">serve&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># terminal 2 (in agent-llamaindex-js/)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">node&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">js&lt;/span> &lt;span class="s2">&amp;#34;Add 11 and 99&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Agent should call the tool and print: 110&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Youâ€™ll see an answer like this.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/llamaindex-rag-agents-javascript/agent-res.png"
width="1418"
height="169"
srcset="https://zinef.github.io/p/llamaindex-rag-agents-javascript/agent-res_hu_8d626c0342613388.png 480w, https://zinef.github.io/p/llamaindex-rag-agents-javascript/agent-res_hu_e9421d36b229d19f.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="839"
data-flex-basis="2013px"
>&lt;/p>
&lt;h2 id="production-considerations">Production Considerations
&lt;/h2>&lt;p>When deploying RAG systems and agents to production, several critical factors must be addressed:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Performance Optimization&lt;/strong>: Implement vector database caching, use connection pooling for database operations, and consider implementing response caching for frequently asked questions.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Security and Privacy&lt;/strong>: Implement proper input sanitization, use environment-specific API keys, implement rate limiting, and ensure sensitive data is properly handled and not logged.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Monitoring and Observability&lt;/strong>: Track query performance, monitor token usage and costs, implement error tracking, and maintain conversation quality metrics.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Scalability&lt;/strong>: Design for horizontal scaling, implement proper load balancing, consider edge deployments for reduced latency, and plan for data partitioning strategies.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="advanced-features-and-extensibility">Advanced Features and Extensibility
&lt;/h2>&lt;p>LlamaIndex.ts supports numerous advanced features that can enhance your applications:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Custom Vector Stores&lt;/strong>: Integration with specialized vector databases like Pinecone, Weaviate, or Qdrant for production-scale deployments.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Multi-modal Capabilities&lt;/strong>: Support for processing images, audio, and other media types alongside text documents.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Fine-tuning Integration&lt;/strong>: Capability to work with custom fine-tuned models for domain-specific applications.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Real-time Updates&lt;/strong>: Implement systems for updating knowledge bases in real-time as new information becomes available.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="references--further-reading">References &amp;amp; Further Reading
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://ts.llamaindex.ai/" target="_blank" rel="noopener"
>LlamaIndex.TS (JS/TS) docs&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.notion.so/RAG-JS-2514e23683188084a34cc5c050a9ca4c?pvs=21" target="_blank" rel="noopener"
>Loading data&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://ts.llamaindex.ai/docs/workflows" target="_blank" rel="noopener"
>LlamaIndex Workflows / agents&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://arxiv.org/abs/2005.11401" target="_blank" rel="noopener"
>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.llamaindex.ai/en/stable/understanding/rag/" target="_blank" rel="noopener"
>LlamaIndex RAG blog&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://huggingface.co/blog/ngxson/make-your-own-rag" target="_blank" rel="noopener"
>Make your own RAG - Huggingface blog&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://huggingface.co/learn/agents-course/unit0/introduction" target="_blank" rel="noopener"
>Huggingface&amp;rsquo;s Agents Course&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>OpenAI Goes Open Source: Introducing GPT-OSS Models</title><link>https://zinef.github.io/p/openai-gpt-oss-models/</link><pubDate>Tue, 05 Aug 2025 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/openai-gpt-oss-models/</guid><description>&lt;img src="https://zinef.github.io/p/openai-gpt-oss-models/open_ai.jpg" alt="Featured image of post OpenAI Goes Open Source: Introducing GPT-OSS Models" />&lt;p>Today marks a significant shift in OpenAI&amp;rsquo;s approach to AI democratization. The company has released their first open-weight models: GPT-OSS-120B and GPT-OSS-20B, bringing state-of-the-art reasoning capabilities directly to developers and researchers worldwide.&lt;/p>
&lt;p>After years of keeping their most advanced models behind API walls, OpenAI is finally embracing the open-source movement that has been thriving with competitors like Meta, Mistral, and DeepSeek. This move isn&amp;rsquo;t just about catching up, it&amp;rsquo;s about making advanced AI accessible to anyone with the hardware to run it.&lt;/p>
&lt;h2 id="what-are-gpt-oss-models">What Are GPT-OSS Models?
&lt;/h2>&lt;p>The GPT-OSS family consists of two models designed specifically for reasoning tasks:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>GPT-OSS-120B&lt;/strong>: A 117-billion parameter model optimized for complex reasoning&lt;/li>
&lt;li>&lt;strong>GPT-OSS-20B&lt;/strong>: A smaller 21-billion parameter model for resource-constrained environments&lt;/li>
&lt;/ul>
&lt;p>Both models use a mixture-of-experts (MoE) architecture with 4-bit quantization (MXFP4), enabling faster inference while maintaining performance. According to OpenAI, these models offer &amp;ldquo;state-of-the-art open-weights reasoning&amp;rdquo; with &amp;ldquo;strong real-world performance comparable to o4-mini&amp;rdquo;.&lt;/p>
&lt;h2 id="technical-capabilities-and-performance">Technical Capabilities and Performance
&lt;/h2>&lt;p>What sets these models apart is their focus on reasoning rather than general language modeling. OpenAI claims they outperform similarly sized models on reasoning through complex tasks, making them particularly suitable for applications requiring logical thinking and problem-solving.&lt;/p>
&lt;p>The 4-bit quantization is particularly interesting from a practical standpoint. This compression technique allows the models to run efficiently on consumer hardware while maintaining most of their reasoning capabilities. Sam Altman noted that the smaller model can even run &amp;ldquo;on your phone&amp;rdquo;, though I&amp;rsquo;d be curious to see the actual performance metrics on mobile hardware.&lt;/p>
&lt;h2 id="local-deployment-possibilities">Local Deployment Possibilities
&lt;/h2>&lt;p>One of the most exciting aspects of these releases is the potential for local deployment. NVIDIA has already announced optimization for RTX GPUs, and reports suggest the models run well on Apple Silicon Macs.&lt;/p>
&lt;p>For developers and researchers, this means:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Privacy&lt;/strong>: Sensitive data never leaves your infrastructure&lt;/li>
&lt;li>&lt;strong>Customization&lt;/strong>: Full control over fine-tuning and adaptation&lt;/li>
&lt;li>&lt;strong>Cost Control&lt;/strong>: No per-token API charges for high-volume applications&lt;/li>
&lt;li>&lt;strong>Offline Operation&lt;/strong>: Models work without internet connectivity&lt;/li>
&lt;/ul>
&lt;p>The hardware requirements will be significant for the larger model, but the 20B version should be accessible to many developers with modern workstations or cloud instances.&lt;/p>
&lt;h2 id="strategic-implications">Strategic Implications
&lt;/h2>&lt;p>This release represents a notable strategy shift for OpenAI. The move positions them to compete directly with Meta, Mistral, and DeepSeek in the open-weight space, acknowledging that closed models alone aren&amp;rsquo;t sufficient to maintain market position.&lt;/p>
&lt;p>OpenAI frames this as part of their mission &amp;ldquo;to put AI in the hands of as many people as possible&amp;rdquo;, but it&amp;rsquo;s also a practical response to the growing success of open-source alternatives. The community has demonstrated that open models can match or exceed proprietary ones in many tasks, and OpenAI seems to be adapting to this reality.&lt;/p>
&lt;h2 id="what-this-means-for-developers">What This Means for Developers
&lt;/h2>&lt;p>If you&amp;rsquo;ve been working exclusively with API-based models, GPT-OSS opens new possibilities:&lt;/p>
&lt;p>&lt;strong>Agentic Applications&lt;/strong>: These reasoning models enable &amp;ldquo;agentic AI applications such as web search, in-depth research and many more&amp;rdquo;. The ability to run reasoning models locally could significantly improve the reliability and cost-effectiveness of AI agents.&lt;/p>
&lt;p>&lt;strong>Research and Experimentation&lt;/strong>: Having full access to model weights enables deeper research into reasoning mechanisms, potential security vulnerabilities, and novel applications that aren&amp;rsquo;t possible with API-only access.&lt;/p>
&lt;p>&lt;strong>Production Flexibility&lt;/strong>: Organizations can now deploy OpenAI-quality reasoning models in environments where API calls aren&amp;rsquo;t feasible or desirable.&lt;/p>
&lt;h2 id="getting-started">Getting Started
&lt;/h2>&lt;p>The models are available through standard open-source channels, and the community has already begun integrating them into popular frameworks. NVIDIA&amp;rsquo;s RTX AI Garage provides optimized versions for their hardware, which should make deployment more straightforward for developers with compatible GPUs.&lt;/p>
&lt;p>For those interested in experimenting, I&amp;rsquo;d recommend starting with the 20B model to understand the capabilities before investing in the hardware needed for the larger version.&lt;/p>
&lt;h2 id="looking-forward">Looking Forward
&lt;/h2>&lt;p>This release feels like a watershed moment for AI accessibility. While OpenAI continues developing frontier models behind closed doors, opening their reasoning models to the community will likely accelerate innovation in AI applications and research.&lt;/p>
&lt;p>The combination of state-of-the-art reasoning capabilities with local deployment flexibility creates opportunities we haven&amp;rsquo;t had before. I&amp;rsquo;m particularly excited to see how the community adapts these models for specialized reasoning tasks and what novel applications emerge.&lt;/p>
&lt;p>As someone who has worked extensively with both open and closed models, I believe this move will ultimately benefit everyone, pushing both open-source development and proprietary research forward through increased competition and collaboration.&lt;/p>
&lt;p>The era of truly accessible, high-quality reasoning AI has begun. The question now is what we&amp;rsquo;ll build with it.&lt;/p>
&lt;h2 id="references">References
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://openai.com/index/introducing-gpt-oss/" target="_blank" rel="noopener"
>OpenAI&amp;rsquo;s Official GPT-OSS Announcement&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://huggingface.co/blog/welcome-openai-gpt-oss" target="_blank" rel="noopener"
>Hugging Face Blog: Welcome GPT OSS&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss/" target="_blank" rel="noopener"
>NVIDIA RTX AI Garage Integration&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://openai.com/open-models/" target="_blank" rel="noopener"
>OpenAI Open Models Page&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>AI-Assisted 3D Design: Exploring Blender-MCP</title><link>https://zinef.github.io/p/blender-mcp/</link><pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/blender-mcp/</guid><description>&lt;img src="https://zinef.github.io/p/blender-mcp/blender_mcp_cover.jpg" alt="Featured image of post AI-Assisted 3D Design: Exploring Blender-MCP" />&lt;p>I&amp;rsquo;ve recently been experimenting with an exciting project at the intersection of AI and 3D design: Blender-MCP, which connects Claude Sonnet or other LLMs to Blender&amp;rsquo;s UI through an MCP server.&lt;/p>
&lt;p>The concept is fascinating - using natural language prompts to create 3D models without touching traditional modeling tools. After seeing impressive demos circulating on social media, I had to try it myself.&lt;/p>
&lt;h2 id="what-works-beautifully">What works beautifully
&lt;/h2>&lt;p>Blender-MCP shines when working with basic geometric shapes. The system understands concepts like &amp;ldquo;create a sphere,&amp;rdquo; &amp;ldquo;add a cylinder,&amp;rdquo; and &amp;ldquo;position a cube&amp;rdquo; remarkably well. It can follow step-by-step instructions to build compositions of these simple elements into more complex structures.&lt;/p>
&lt;p>In one experiment, I built a simple castle using progressive prompts, guiding the AI through the process of creating towers, walls, and architectural details. The results were promising - while not photorealistic, the AI understood the concept and executed a recognizable castle structure.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/blender-mcp/castle.png"
width="2557"
height="1374"
srcset="https://zinef.github.io/p/blender-mcp/castle_hu_526c500917504314.png 480w, https://zinef.github.io/p/blender-mcp/castle_hu_3217e96eae2968b.png 1024w"
loading="lazy"
alt=" A simple castle built using progressive prompts"
class="gallery-image"
data-flex-grow="186"
data-flex-basis="446px"
>&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/blender-mcp/mars_rover.png"
width="2559"
height="1377"
srcset="https://zinef.github.io/p/blender-mcp/mars_rover_hu_3a4f530d9aca0d71.png 480w, https://zinef.github.io/p/blender-mcp/mars_rover_hu_ce0d03f03f272676.png 1024w"
loading="lazy"
alt=" Mars rover lego using progressive prompts"
class="gallery-image"
data-flex-grow="185"
data-flex-basis="446px"
>&lt;/p>
&lt;h2 id="current-limitations">Current limitations
&lt;/h2>&lt;p>Like many cutting-edge tools, Blender-MCP is still evolving. Complex organic shapes or highly detailed models remain challenging. The system works best when you break down complex ideas into smaller, manageable steps using simple geometry as building blocks.&lt;/p>
&lt;p>I found the most success when taking an iterative approach - starting with basic shapes and gradually refining them through additional prompts, rather than expecting perfect results from a single detailed instruction.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/blender-mcp/limits.png"
width="1681"
height="994"
srcset="https://zinef.github.io/p/blender-mcp/limits_hu_42eda728e8364bf8.png 480w, https://zinef.github.io/p/blender-mcp/limits_hu_dbb519721ab35f13.png 1024w"
loading="lazy"
class="gallery-image"
data-flex-grow="169"
data-flex-basis="405px"
>&lt;/p>
&lt;h2 id="the-bigger-picture">The bigger picture
&lt;/h2>&lt;p>What excites me most about Blender-MCP isn&amp;rsquo;t just what it can do today, but what it represents for the future of creative workflows. The project demonstrates how AI can lower barriers to 3D design, potentially making these tools accessible to those without traditional modeling expertise.&lt;/p>
&lt;p>The open-source community has already begun enhancing the project with marketplaces for ready-to-use models and additional plugins, showing the power of collaborative innovation.&lt;/p>
&lt;h2 id="combining-ai-tools-for-superior-results">Combining AI Tools for Superior Results
&lt;/h2>&lt;p>What I&amp;rsquo;ve discovered is that the true power of AI-driven 3D design emerges when combining complementary tools. While Blender-MCP excels with geometric shapes and positioning, it currently struggles with complex organic forms. This is where pairing it with state-of-the-art ML models like &lt;strong>Hunyuan3D-2&lt;/strong> creates a workflow greater than the sum of its parts.&lt;/p>
&lt;p>&lt;strong>Hunyuan3D-2: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation&lt;/strong> deserves special recognition. This remarkable model can generate detailed 3D assets from simple 2D images with impressive fidelity. The results are surprisingly sophisticated for an AI-generated model, especially considering how new this technology is.&lt;/p>
&lt;p>In a recent experiment, I tested this workflow with a figurine of Luffy. I first used Hunyuan3D-2 to generate the base 3D model from a 2D reference, then imported it into Blender. From there, I leveraged Blender-MCP&amp;rsquo;s natural language interface to enhance and smooth the results. The combined approach allowed me to achieve in minutes what would have taken hours of manual modeling.&lt;/p>
&lt;p>This hybrid workflow represents what I believe is the future of AI-assisted creation - not replacing human creativity, but amplifying it by handling technical barriers and time-consuming tasks. By strategically combining AI tools based on their strengths, designers can save significant time while achieving higher quality results.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/blender-mcp/workflow.png"
width="1188"
height="1049"
srcset="https://zinef.github.io/p/blender-mcp/workflow_hu_768c007a178de45f.png 480w, https://zinef.github.io/p/blender-mcp/workflow_hu_90fbb1d5a89cd36c.png 1024w"
loading="lazy"
alt=" "
class="gallery-image"
data-flex-grow="113"
data-flex-basis="271px"
>&lt;/p>
&lt;h2 id="looking-forward">Looking forward
&lt;/h2>&lt;p>As MCP (Model Context Protocol) technology continues to develop, we&amp;rsquo;ll likely see rapid improvements in these tools&amp;rsquo; capabilities. What requires multiple careful prompts today might be achieved with a single instruction tomorrow.&lt;/p>
&lt;p>If you&amp;rsquo;re interested in exploring this space, I encourage you to check out the Blender-MCP project and Anthropic&amp;rsquo;s documentation on MCP. Even if you encounter limitations, contributing feedback helps advance these technologies.&lt;/p>
&lt;h2 id="references">References
&lt;/h2>&lt;ul>
&lt;li>Blender-mcp : &lt;a class="link" href="https://github.com/ahujasid/blender-mcp" target="_blank" rel="noopener"
>https://github.com/ahujasid/blender-mcp&lt;/a>&lt;/li>
&lt;li>Model Context Protocol : &lt;a class="link" href="https://www.anthropic.com/news/model-context-protocol" target="_blank" rel="noopener"
>https://www.anthropic.com/news/model-context-protocol&lt;/a>&lt;/li>
&lt;li>Hunyuan3D-2 github repo: &lt;a class="link" href="https://github.com/Tencent/Hunyuan3D-2" target="_blank" rel="noopener"
>https://github.com/Tencent/Hunyuan3D-2&lt;/a>&lt;/li>
&lt;li>Hunyuan3D-2 HF Spaces : &lt;a class="link" href="https://huggingface.co/spaces/tencent/Hunyuan3D-2" target="_blank" rel="noopener"
>https://huggingface.co/spaces/tencent/Hunyuan3D-2&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>The Hidden Threat: Using Steganography to Hide Malicious Payloads in Deep Learning Models</title><link>https://zinef.github.io/p/tensorstego/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/tensorstego/</guid><description>&lt;img src="https://zinef.github.io/p/tensorstego/tensor_stego_cover.jpg" alt="Featured image of post The Hidden Threat: Using Steganography to Hide Malicious Payloads in Deep Learning Models" />&lt;h2 id="introduction">Introduction
&lt;/h2>&lt;p>As deep learning models become increasingly integrated into critical systems, the security implications of these AI models demand closer analysis. While much attention has focused on adversarial attacks and model poisoning, a more subtle threat lurks in the architecture of neural networks themselves: tensor steganography. This technique allows malicious actors to embed hidden payloads directly within model weights without significantly affecting performance, creating a potential vector for distributing malware that bypasses traditional security measures.&lt;/p>
&lt;p>In this article, I&amp;rsquo;ll explore how tensor steganography works, demonstrate its feasibility in popular models like ResNet18, and explain why security professionals and ML engineers should be concerned about this emerging threat vector.&lt;/p>
&lt;h2 id="what-is-tensor-steganography">What is Tensor Steganography?
&lt;/h2>&lt;p>Steganography is the practice of hiding information within other non-secret data or a physical object to avoid detection. Unlike encryption, which makes data unreadable but visible, steganography conceals the very existence of the hidden data.&lt;/p>
&lt;p>Tensor steganography applies this concept to neural networks by embedding data in the least significant bits of the floating-point values that make up model weights. These minor alterations are virtually undetectable through casual inspection and have minimal impact on model performance, making them an ideal hiding place for malicious code.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/tensorstego/workflow.png"
width="792"
height="548"
srcset="https://zinef.github.io/p/tensorstego/workflow_hu_27998fe2a5a235ba.png 480w, https://zinef.github.io/p/tensorstego/workflow_hu_a9d31b72b89d71f2.png 1024w"
loading="lazy"
alt="Overall Workflow (from : EvilModel: Hiding Malware Inside of Neural
Network Models. )"
class="gallery-image"
data-flex-grow="144"
data-flex-basis="346px"
>&lt;/p>
&lt;h2 id="feasibility-analysis-the-resnet18-case-study">Feasibility Analysis: The ResNet18 Case Study
&lt;/h2>&lt;p>To understand the risk, let&amp;rsquo;s analyze the capacity for hidden data in a relatively small model like ResNet18. The largest convolutional layer in ResNet18 contains approximately 9.4MB of floating-point values . By manipulating just the least significant bits of each float&amp;rsquo;s mantissa, we can embed surprising amounts of data:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Bits Modified Per Float&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Storage Capacity&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1-bit&lt;/td>
&lt;td>294.9 kB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2-bits&lt;/td>
&lt;td>589.8 kB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3-bits&lt;/td>
&lt;td>884.7 kB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4-bits&lt;/td>
&lt;td>1.2 MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5-bits&lt;/td>
&lt;td>1.5 MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6-bits&lt;/td>
&lt;td>1.8 MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>7-bits&lt;/td>
&lt;td>2.1 MB&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8-bits&lt;/td>
&lt;td>2.4 MB&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;img src="https://zinef.github.io/p/tensorstego/capacity-bar-chart-updated.svg"
loading="lazy"
>
This analysis reveals that even a modest model like ResNet18 can conceal up to 2.4MB of data by modifying just 8 bits per float in a single layer. Larger models commonly used in production environments could potentially hide much more â€” up to 9MB of malicious code using only 3 bits per float in a single layer.&lt;/p>
&lt;h2 id="implementation-how-tensor-steganography-works">Implementation: How Tensor Steganography Works
&lt;/h2>&lt;p>Below is a Python implementation that demonstrates how to embed an arbitrary payload into a PyTorch model using steganography. This is a simple and naive example for illustrative purposes. In practice, a malicious actor could employ far more sophisticated techniques, making the detection and analysis of such hidden data significantly more challenging.&lt;/p>
&lt;h3 id="1-import-dependencies">1. Import Dependencies
&lt;/h3>&lt;p>We first import the required libraries:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">struct&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">hashlib&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pathlib&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Path&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="2-function-definition-and-validations">2. Function Definition and Validations
&lt;/h3>&lt;p>We define the function and validate the bit-depth parameter &lt;code>n&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">tensor_stego&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">payload_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Embeds a payload inside the least significant bits (LSB) of the weights in a PyTorch model.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Args:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> model_path (Path): Path to the PyTorch model (.pt or .pth).
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> payload_path (Path): Path to the binary payload file.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> n (int): Number of LSBs to use (1-8). Default is 1.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Returns:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> bool: True if embedding was successful, False otherwise.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;n must be between 1 and 8.&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="3-load-the-model">3. Load the Model
&lt;/h3>&lt;p>We load the model :&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">map_location&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;cpu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="4-read--prepare-the-payload">4. Read &amp;amp; Prepare the Payload
&lt;/h3>&lt;p>Before embedding, we format the payload to include:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>File size&lt;/strong> (so it can be reconstructed correctly)&lt;/li>
&lt;li>&lt;strong>SHA-256 hash&lt;/strong> (for integrity verification)&lt;/li>
&lt;li>&lt;strong>The actual payload data&lt;/strong>&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;rb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">payload_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getsize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">payload_hash&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hashlib&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sha256&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_data&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">hexdigest&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Pack size (4 bytes) + hash (64 bytes) + actual data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">payload&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">struct&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pack&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;i&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">payload_size&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">payload_hash&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">payload_data&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="5-convert-payload-to-bit-stream">5. Convert Payload to Bit Stream
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">bits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unpackbits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frombuffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Ensure the bit stream is a multiple of `n` by padding with zeros&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">padding_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">n&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">bits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pad&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">padding_size&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">constant_values&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">bits_iter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">iter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="6-embed-the-bits-into-the-models-tensors">6. Embed the Bits into the Modelâ€™s Tensors
&lt;/h3>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tensor_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">numpy&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Check if the tensor has enough capacity to store the payload&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">continue&lt;/span> &lt;span class="c1"># Skip this tensor if it&amp;#39;s too small&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Embedding payload into layer: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Compute the LSB mask &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mh">0xff&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">itemsize&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">mask&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="mh">0xff&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mask&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Create a read/write iterator for the tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">with&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nditer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint32&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">,&lt;/span> &lt;span class="n">op_flags&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;readwrite&amp;#34;&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">tensor_iterator&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Iterate over float values in tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">tensor_iterator&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Get next bits to embed from the payload&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lsb_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lsb_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">lsb_value&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">next&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits_iter&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span> &lt;span class="ne">StopIteration&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">assert&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Save the model back to disk&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Embed the payload bits into the float&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bitwise_and&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mask&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bitwise_or&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lsb_value&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Update the float value in the tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tensor_iterator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">return&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="7-save-the-modified-model">7. Save the Modified Model
&lt;/h3>&lt;p>The model is automatically saved inside the loop when the entire payload is embedded. If embedding fails, we return &lt;code>False&lt;/code>.&lt;/p>
&lt;p>&lt;em>&lt;strong>N.B : This code includes a verification mechanism (SHA256 hash) to ensure the payload can be correctly extracted later. The payload format consists of the data size, a hash for verification, and the actual content.&lt;/strong>&lt;/em>&lt;/p>
&lt;p>Below is the full script in one place for convenience:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;span class="lnt">70
&lt;/span>&lt;span class="lnt">71
&lt;/span>&lt;span class="lnt">72
&lt;/span>&lt;span class="lnt">73
&lt;/span>&lt;span class="lnt">74
&lt;/span>&lt;span class="lnt">75
&lt;/span>&lt;span class="lnt">76
&lt;/span>&lt;span class="lnt">77
&lt;/span>&lt;span class="lnt">78
&lt;/span>&lt;span class="lnt">79
&lt;/span>&lt;span class="lnt">80
&lt;/span>&lt;span class="lnt">81
&lt;/span>&lt;span class="lnt">82
&lt;/span>&lt;span class="lnt">83
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">struct&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">hashlib&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pathlib&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Path&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torch&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">tensor_stego&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">payload_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bool&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Embeds a payload inside the least significant bits (LSB) of the weights in a PyTorch model.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Args:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> model_path (Path): Path to the PyTorch model (.pt or .pth).
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> payload_path (Path): Path to the binary payload file.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> n (int): Number of LSBs to use (1-8). Default is 1.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Returns:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> bool: True if embedding was successful, False otherwise.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;n must be between 1 and 8.&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">map_location&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;cpu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;rb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">file&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getsize&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload_hash&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hashlib&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sha256&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_data&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">hexdigest&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Pack size (4 bytes) + hash (64 bytes) + actual data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">struct&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pack&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;i&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">payload_size&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">payload_hash&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">payload_data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">bits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unpackbits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">frombuffer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Ensure the bit stream is a multiple of `n` by padding with zeros&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">padding_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="o">%&lt;/span> &lt;span class="n">n&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">bits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pad&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">padding_size&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">constant_values&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">bits_iter&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">iter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tensor_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">numpy&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Check if the tensor has enough capacity to store the payload&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">size&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">continue&lt;/span> &lt;span class="c1"># Skip this tensor if it&amp;#39;s too small&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Embedding payload into layer: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Compute the LSB mask &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mh">0xff&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">itemsize&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">mask&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="mh">0xff&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mask&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Create a read/write iterator for the tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">with&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nditer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint32&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">,&lt;/span> &lt;span class="n">op_flags&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;readwrite&amp;#34;&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">tensor_iterator&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Iterate over float values in tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">tensor_iterator&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Get next bits to embed from the payload&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lsb_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lsb_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">lsb_value&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">next&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">bits_iter&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span> &lt;span class="ne">StopIteration&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">assert&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Save the model back to disk&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Embed the payload bits into the float&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bitwise_and&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">mask&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bitwise_or&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">lsb_value&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Update the float value in the tensor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tensor_iterator&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Here&amp;rsquo;s a test snippet using &lt;strong>ResNet18&lt;/strong> to verify &lt;code>tensor_stego()&lt;/code> :&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">torchvision.models&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">models&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Define paths&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;resnet18.pth&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">payload_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;payload.bin&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Load a pretrained ResNet18 model and save its state_dict&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">models&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">resnet18&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pretrained&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">state_dict&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="n">model_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Generate a small binary payload&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="nb">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">payload_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;wb&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">f&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">write&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">b&lt;/span>&lt;span class="s2">&amp;#34;The One Piece is real !&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># Example hidden message&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">success&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tensor_stego&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">payload_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://zinef.github.io/p/tensorstego/res1.png"
width="844"
height="190"
srcset="https://zinef.github.io/p/tensorstego/res1_hu_3be774c4f1fbe107.png 480w, https://zinef.github.io/p/tensorstego/res1_hu_7a3441109ea1c7b9.png 1024w"
loading="lazy"
alt="Tensor stego test run results"
class="gallery-image"
data-flex-grow="444"
data-flex-basis="1066px"
>&lt;/p>
&lt;p>Hereâ€™s the reverse function to &lt;strong>extract the hidden payload&lt;/strong> from the PyTorch model. This function will:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Load the model&lt;/strong> from the given path.&lt;/li>
&lt;li>&lt;strong>Extract the LSBs&lt;/strong> of the weights to reconstruct the payload.&lt;/li>
&lt;li>&lt;strong>Verify the extracted payload&lt;/strong> by checking its SHA-256 hash.&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">extract_payload&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="nb">int&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&amp;gt;&lt;/span> &lt;span class="nb">bytes&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Extracts a hidden payload from the least significant bits (LSB) of the weights in a PyTorch model.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Args:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> model_path (Path): Path to the PyTorch model (.pt or .pth).
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> n (int): Number of LSBs used for embedding (1-8).
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> Returns:
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> bytes: Extracted payload if successful, None otherwise.
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="n">n&lt;/span> &lt;span class="o">&amp;lt;=&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">raise&lt;/span> &lt;span class="ne">ValueError&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;n must be between 1 and 8.&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">map_location&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">torch&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">device&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;cpu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">extracted_bits&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tensor_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cpu&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">numpy&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Skip scalar tensors (0D)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ndim&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Ensure data is in a format that supports bitwise operations&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">tensor_data_flat&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tensor_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ravel&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">view&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint32&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">tensor_data_flat&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Extract LSBs from the float&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lsb_value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="p">((&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="o">&amp;lt;&amp;lt;&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">extracted_bits&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extend&lt;/span>&lt;span class="p">([(&lt;/span>&lt;span class="n">lsb_value&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;amp;&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">reversed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="p">))])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Convert bitstream to bytes&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">extracted_bytes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">packbits&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">extracted_bits&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">))&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tobytes&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Extract payload size (first 4 bytes)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">struct&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">unpack&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;i&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">extracted_bytes&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">])[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">payload_hash&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">extracted_bytes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">68&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">extracted_payload&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">extracted_bytes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">68&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">68&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">payload_size&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Verify integrity&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">computed_hash&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">hashlib&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sha256&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">extracted_payload&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">hexdigest&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">encode&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">computed_hash&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">payload_hash&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Payload successfully extracted and verified!&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">extracted_payload&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Payload extraction failed: Hash mismatch.&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="kc">None&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">extracted_payload&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">extract_payload&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;resnet18.pth&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="n">extracted_payload&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Extracted Message:&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">extracted_payload&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">decode&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">errors&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;ignore&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://zinef.github.io/p/tensorstego/res2.png"
width="844"
height="202"
srcset="https://zinef.github.io/p/tensorstego/res2_hu_afd9f3e93bf6437b.png 480w, https://zinef.github.io/p/tensorstego/res2_hu_65ae344575361bba.png 1024w"
loading="lazy"
alt="Reverse function run results."
class="gallery-image"
data-flex-grow="417"
data-flex-basis="1002px"
>&lt;/p>
&lt;h2 id="security-implications">Security Implications
&lt;/h2>&lt;p>The ability to hide executable code within model weights presents several concerning security implications:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Bypassing Security Scanning&lt;/strong>: Traditional malware detection tools don&amp;rsquo;t inspect ML model weights, allowing embedded malicious code to evade detection.&lt;/li>
&lt;li>&lt;strong>Supply Chain Attacks&lt;/strong>: Pre-trained models downloaded from public repositories could contain hidden payloads that activate when the model is loaded.&lt;/li>
&lt;li>&lt;strong>Persistent Backdoors&lt;/strong>: Since model weights are rarely inspected or modified after deployment, embedded code could remain undetected for extended periods.&lt;/li>
&lt;li>&lt;strong>Execution Pathways&lt;/strong>: Concealing data within tensors is only the first step. The real threat emerges when this hidden payload is automatically extracted and executed, potentially exploiting vulnerabilities in how ML frameworks deserialize and handle model parameters. Prior research has demonstrated how adversaries can craft malicious models that trigger arbitrary code execution upon loading, bridging the gap between passive data hiding and active system compromise. For those interested in the practical exploitation of this vulnerability, &lt;a class="link" href="https://hiddenlayer.com/innovation-hub/weaponizing-machine-learning-models-with-ransomware/" target="_blank" rel="noopener"
>this article&lt;/a> provides a detailed breakdown of real-world attack scenarios, including a concrete example of how serialization flaws in PyTorch models can be leveraged for execution.&lt;/li>
&lt;/ol>
&lt;h2 id="defensive-measures">Defensive Measures
&lt;/h2>&lt;p>As a data professional responsible for model security, consider implementing these comprehensive protective measures:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Source Verification&lt;/strong>: Only use models from trusted sources with verified signatures. Implement model signing as a means of performing integrity checking to detect tampering and corruption.&lt;/li>
&lt;li>&lt;strong>Weight Analysis&lt;/strong>: Develop tools to analyze the distribution of least significant bits in model weights, which may reveal statistical anomalies indicating hidden data. Techniques such as entropy and Z-score analysis can help detect low-entropy payloads, though encrypted payloads remain challenging to identify.&lt;/li>
&lt;li>&lt;strong>Sandboxed Loading&lt;/strong>: Load models in isolated environments with limited permissions to prevent potential code execution. This is especially critical when using pre-trained models downloaded from the internet, as current anti-malware solutions may not detect all code execution techniques.&lt;/li>
&lt;li>&lt;strong>Security Scanning Tools&lt;/strong>: Utilize specialized tools like TrailOfBits&amp;rsquo; Fickling to detect simple attempts to exploit ML serialization formats. Monitor repositories like HuggingFace that have implemented security scanners for user-supplied models.&lt;/li>
&lt;li>&lt;strong>Format Selection&lt;/strong>: Choose storage formats that offer enhanced security by avoiding data deserialization flaws, which are particularly vulnerable to exploitation.&lt;/li>
&lt;li>&lt;strong>EDR Solutions&lt;/strong>: Deploy and properly tune Endpoint Detection and Response solutions to gain better insight into attacks as they occur, particularly for detecting advanced payloads delivered via ML models.&lt;/li>
&lt;li>&lt;strong>Regular Security Audits&lt;/strong>: Conduct periodic security audits of your AI infrastructure, focusing on the integrity of deployed models and potential vulnerabilities in your ML pipeline.&lt;/li>
&lt;/ol>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>Tensor steganography represents a sophisticated attack vector that could transform seemingly benign deep learning models into vehicles for malware distribution. As ML systems continue to proliferate across critical infrastructure, security professionals must expand their threat models to include these novel attack vectors.&lt;/p>
&lt;p>The research demonstrates that even small models contain sufficient capacity to hide substantial malicious payloads with minimal impact on model performance. As larger models become standard, this capacity increases significantlyâ€”amplifying the potential threat.&lt;/p>
&lt;p>For organizations developing or deploying ML systems, understanding and mitigating these risks should become an essential component of AI security protocols. The intersection of deep learning and cybersecurity continues to reveal new challenges that require vigilance and innovative defensive approaches.&lt;/p>
&lt;p>For a more comprehensive understanding of this threat, I encourage readers to explore the references which provides detailed explanations of payload exploitation techniques, practical demonstrations, and extensive references. This in-depth resources offers security professionals the technical insights needed to develop robust defensive measures against this type of attacks.&lt;/p>
&lt;h2 id="references-">References :
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://hiddenlayer.com/innovation-hub/weaponizing-machine-learning-models-with-ransomware/" target="_blank" rel="noopener"
>Weaponizing ML Models with Ransomware&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://cse.buffalo.edu/~wenyaoxu/papers/conference/xu-acsac2020.pdf" target="_blank" rel="noopener"
>StegoNet: Turn Deep Neural Network into a Stegomalware&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://arxiv.org/pdf/2107.08590" target="_blank" rel="noopener"
>EvilModel: Hiding Malware Inside of Neural Network Models&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://arxiv.org/abs/2106.08970" target="_blank" rel="noopener"
>Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.darkreading.com/application-security/hugging-face-ai-platform-100-malicious-code-execution-models" target="_blank" rel="noopener"
>https://www.darkreading.com/application-security/hugging-face-ai-platform-100-malicious-code-execution-models&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://medium.com/@limbagoa/securing-the-ai-supply-chain-051f8d43c5c4" target="_blank" rel="noopener"
>https://medium.com/@limbagoa/securing-the-ai-supply-chain-051f8d43c5c4&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.techrepublic.com/article/pytorch-ml-compromised/" target="_blank" rel="noopener"
>https://www.techrepublic.com/article/pytorch-ml-compromised/&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide</title><link>https://zinef.github.io/p/lmianalysis/</link><pubDate>Sat, 17 Feb 2024 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/lmianalysis/</guid><description>&lt;img src="https://zinef.github.io/p/lmianalysis/biospecimen-whole-slide-image-1.png" alt="Featured image of post How Can We Analyze Large Medical Images to Detect Brain Tumors? A Practical Guide" />&lt;h2 id="introduction">Introduction
&lt;/h2>&lt;p>Brain tumors are among the most aggressive and lethal forms of cancer, and early detection is crucial for improving patient outcomes. However, analyzing medical images to diagnose and classify brain tumors presents several challenges due to the sheer size and complexity of whole-slide images (WSIs). In this article, I will share insights from my project, &lt;em>Converting Large Medical Images to Embeddings for Training Classifier Models&lt;/em>, where I leveraged deep learning techniques to process high-resolution medical images efficiently. This is not just a technical breakdown but a real-world experience of tackling the problem, highlighting key lessons and takeaways.&lt;/p>
&lt;h2 id="the-challenge-of-large-scale-medical-image-analysis">The Challenge of Large-Scale Medical Image Analysis
&lt;/h2>&lt;p>Medical images, particularly WSIs, are massive, often exceeding 100,000 pixels in resolution. Traditional image classification methods struggle to process such data due to memory constraints and computational complexity. My goal was to convert these high-dimensional images into meaningful embeddings that could be used for training classifier models to predict immune invasion stages in glioblastomaâ€”a highly aggressive brain tumor.&lt;/p>
&lt;h3 id="key-challenges">Key Challenges
&lt;/h3>&lt;ol>
&lt;li>&lt;strong>Data Size &amp;amp; Complexity:&lt;/strong> WSIs are gigapixel images that require efficient handling and storage.&lt;/li>
&lt;li>&lt;strong>Annotation Scarcity:&lt;/strong> Unlike natural images, medical images require expert annotations, which are often limited.&lt;/li>
&lt;li>&lt;strong>Feature Extraction:&lt;/strong> Extracting meaningful representations from these images without losing critical information.&lt;/li>
&lt;li>&lt;strong>Computational Constraints:&lt;/strong> Training deep learning models on such large images is resource-intensive.&lt;/li>
&lt;/ol>
&lt;h2 id="the-solution-transforming-images-into-embeddings">The Solution: Transforming Images into Embeddings
&lt;/h2>&lt;p>To address these challenges, I explored and adapted two state-of-the-art deep learning approaches:&lt;/p>
&lt;h3 id="deep-attention-multiple-instance-survival-learning-deepattnmisl">&lt;strong>Deep Attention Multiple-Instance Survival Learning (DeepAttnMISL)&lt;/strong>
&lt;/h3>&lt;p>DeepAttnMISL is a multiple-instance learning (MIL) approach designed for survival prediction from WSIs. Instead of classifying entire images at once, it breaks them into smaller regions (instances) and learns representations using an attention-based mechanism. Key steps included:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Patch Extraction &amp;amp; Clustering:&lt;/strong> Extracting patches from WSIs and grouping them into phenotype clusters.&lt;/li>
&lt;li>&lt;strong>Feature Extraction via CNNs:&lt;/strong> Using a pre-trained VGG model to generate feature embeddings for each patch.&lt;/li>
&lt;li>&lt;strong>Attention-Based Pooling:&lt;/strong> Aggregating patch-level information using an attention-based MIL pooling layer to make patient-level predictions.&lt;/li>
&lt;li>&lt;strong>Final Classification:&lt;/strong> Using the learned embeddings to train a classifier model to predict immune invasion stages (A, B, C, D).&lt;/li>
&lt;/ul>
&lt;h3 id="vision-transformers-vits">&lt;strong>Vision Transformers (ViTs)&lt;/strong>
&lt;/h3>&lt;p>Inspired by their success in NLP, I also explored Vision Transformers (ViTs), which process images as sequences of patches rather than relying on convolutions. ViTs leverage self-attention mechanisms to capture long-range dependencies, making them particularly suited for analyzing complex medical images.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Patch Tokenization:&lt;/strong> Splitting the large image into smaller fixed-size patches.&lt;/li>
&lt;li>&lt;strong>Embedding Generation:&lt;/strong> Encoding each patch into a vector representation.&lt;/li>
&lt;li>&lt;strong>Self-Attention Mechanism:&lt;/strong> Learning relationships between different patches to detect patterns indicative of tumor presence.&lt;/li>
&lt;li>&lt;strong>Classifier Training:&lt;/strong> Using the learned representations to train a predictive model.&lt;/li>
&lt;/ul>
&lt;h2 id="key-takeaways">Key Takeaways
&lt;/h2>&lt;h3 id="the-importance-of-representation-learning">&lt;strong>The Importance of Representation Learning&lt;/strong>
&lt;/h3>&lt;p>Converting images into embeddings significantly reduced the computational burden while preserving essential features. Choosing the right architecture for embedding extraction was crucialâ€”DeepAttnMISL provided structured phenotype-based representations, while ViTs captured global dependencies.&lt;/p>
&lt;h3 id="attention-mechanisms-enhance-interpretability">&lt;strong>Attention Mechanisms Enhance Interpretability&lt;/strong>
&lt;/h3>&lt;p>Using attention-based pooling allowed us to identify the most critical regions of the WSIs, improving both accuracy and interpretability. This was particularly useful for medical experts who need to understand model predictions.&lt;/p>
&lt;h3 id="pretrained-models-save-time--resources">&lt;strong>Pretrained Models Save Time &amp;amp; Resources&lt;/strong>
&lt;/h3>&lt;p>Instead of training deep networks from scratch, leveraging pretrained models (e.g., VGG, ResNet) for feature extraction proved highly effective. Fine-tuning these models with domain-specific data further improved performance.&lt;/p>
&lt;h3 id="computational-constraints-are-a-real-challenge">&lt;strong>Computational Constraints Are a Real Challenge&lt;/strong>
&lt;/h3>&lt;p>Processing high-resolution WSIs required significant memory and GPU resources. Using techniques like patch extraction, dimensionality reduction, and efficient batching helped mitigate these challenges.&lt;/p>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>Analyzing medical images for brain tumor detection is a complex but highly impactful challenge. By leveraging DeepAttnMISL and Vision Transformers, we can efficiently extract meaningful embeddings that improve classification accuracy while reducing computational costs. This project highlighted the power of attention mechanisms in deep learning and underscored the importance of adapting models to the unique constraints of medical imaging.&lt;/p>
&lt;p>For those interested in deep learning applications in healthcare, this field offers vast opportunities to push the boundaries of AI-driven diagnostics. Whether you&amp;rsquo;re a researcher, practitioner, or enthusiast, the key takeaway is clearâ€”smart representation learning is the future of medical image analysis.&lt;/p>
&lt;hr>
&lt;p>&lt;em>What are your thoughts on AI in medical imaging? Have you worked on similar projects? Let&amp;rsquo;s discuss in the comments!&lt;/em>&lt;/p></description></item><item><title>MLOps: Introduction, Definitions and Best Practices</title><link>https://zinef.github.io/p/mlops_6_23/</link><pubDate>Mon, 19 Jun 2023 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/mlops_6_23/</guid><description>&lt;img src="https://zinef.github.io/p/mlops_6_23/MLOps-DevOps.webp" alt="Featured image of post MLOps: Introduction, Definitions and Best Practices" />&lt;h2 id="introduction">Introduction
&lt;/h2>&lt;p>We hear more and more about MLOps. This practice, inspired by DevOps, aims to unify the tasks of developing Machine Learning applications with those of operations.&lt;/p>
&lt;p>In this article, we will see what MLOps is, how it can be practiced and what tools are available to practice it.&lt;/p>
&lt;p>In 2020, each person created at least 1.7 MB of data each second, according to techjury. That&amp;rsquo;s sound good for data scientists since there are so many theories and ideas to investigate, play with, and numerous findings and models to make.&lt;/p>
&lt;p>However, if we want to take this seriously and have these models interact with real-world business challenges and people, we must address the basics first, like acquiring and cleaning large amounts of data, setting up tracking and versioning for experiments and model training runs, setting up the deployment and monitoring pipelines for the models that do get to production.&lt;/p>
&lt;p>Similar challenges occurred in the past when we tried to grow traditional software systems to accommodate additional users. DevOps provided a solution in the form of a set of practices for building, testing, deploying, and running large-scale software systems. DevOps shortened development times, enhanced deployment velocity, and made system releases auditable and durable.&lt;/p>
&lt;p>That bring us to MLOps. It was formed at the junction of DevOps, Data Engineering, and Machine Learning, and while the concept is similar to DevOps, the implementation differs. ML systems are more experimental in nature, with additional components that are far more difficult to develop and run.&lt;/p>
&lt;h2 id="what-is-mlops">What is MLOps?
&lt;/h2>&lt;p>MLOps is the operationalization of Machine Learning model management. This aims to create an end-to-end process for creating, implementing and managing repeatable, testable and scalable machine learning models. MLOps aims to:&lt;/p>
&lt;ul>
&lt;li>Unify the machine learning delivery cycle and the application development cycle&lt;/li>
&lt;li>Automation of Machine Learning tests (Data Validation, model testing, model integration testing, etc)&lt;/li>
&lt;li>Enables the application of agile principles to the Machine Learning project&lt;/li>
&lt;li>Supports model creation in CI/CD&lt;/li>
&lt;li>Reduces the technical debt of ML models&lt;/li>
&lt;li>Must be independent of languages, framework, platform, etc.&lt;/li>
&lt;/ul>
&lt;p>If there is anything to remember, it is that: MLOps is a set of practices that is intended to be as agile as possible and that must be based on the automation of the delivery and continuous integration processes of ML applications&lt;/p>
&lt;p>The key phases of MLOps are:&lt;/p>
&lt;ul>
&lt;li>Data gathering&lt;/li>
&lt;li>Data analysis&lt;/li>
&lt;li>Data transformation/preparation&lt;/li>
&lt;li>Model training &amp;amp; development&lt;/li>
&lt;li>Model validation&lt;/li>
&lt;li>Model serving&lt;/li>
&lt;li>Model monitoring&lt;/li>
&lt;li>Model re-training.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://zinef.github.io/p/mlops_6_23/mlops_cycle.png"
width="1366"
height="768"
srcset="https://zinef.github.io/p/mlops_6_23/mlops_cycle_hu_d5cdb6e8ade7612.png 480w, https://zinef.github.io/p/mlops_6_23/mlops_cycle_hu_6ee3e7024c6f0aac.png 1024w"
loading="lazy"
alt="MLOps cycle"
class="gallery-image"
data-flex-grow="177"
data-flex-basis="426px"
>&lt;/p>
&lt;h3 id="devops--mlops">DevOps &amp;amp; MLOps
&lt;/h3>&lt;p>DevOps is a set of activities aimed at shortening the development life of a system and providing continuous delivery of high quality software. DevOps and MLOps both aim to bring software into a repeatable and fault tolerant workflow, but in MLOps that software also has a machine learning component.&lt;/p>
&lt;p>Before deep diving into the comparison of DevOps and MLOps let&amp;rsquo;s recall what is the DevOps Cycle&lt;/p>
&lt;p>As teams strive for a quicker code-build-deploy loop, DevOps is a crucial concept in practically all successful IT projects. This gives teams the ability to deploy new features more quickly, allowing them to complete projects faster and with a higher quality final result. However, without adequate DevOps methods, teams face manual work, inability to test, and, as a result, dangerous production deployments.&lt;/p>
&lt;p>An ideal DevOps cycle will include the following five important pillars for a successful project (&lt;a class="link" href="https://www.youtube.com/watch?v=uTEL8Ff1Zvk%29" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=uTEL8Ff1Zvk)&lt;/a>:&lt;/p>
&lt;ul>
&lt;li>Reduce organizational silos&lt;/li>
&lt;li>Accept failure as normal&lt;/li>
&lt;li>Implement gradual changes&lt;/li>
&lt;li>Leverage tooling and automation&lt;/li>
&lt;li>Measure everything&lt;/li>
&lt;/ul>
&lt;div class="video-wrapper">
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/uTEL8Ff1Zvk"
allowfullscreen
title="YouTube Video"
>
&lt;/iframe>
&lt;/div>
&lt;p>And the common DevOps cycle that includes all these pillars looks like this:&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/mlops_6_23/schema-devops.webp"
width="850"
height="350"
srcset="https://zinef.github.io/p/mlops_6_23/schema-devops_hu_c802a00d1ba360e2.webp 480w, https://zinef.github.io/p/mlops_6_23/schema-devops_hu_b0788bad4f8f6096.webp 1024w"
loading="lazy"
alt="Dev &amp;#43; Ops = DevOps!"
class="gallery-image"
data-flex-grow="242"
data-flex-basis="582px"
>&lt;/p>
&lt;h3 id="comparison">Comparison
&lt;/h3>&lt;h4 id="cycle">Cycle
&lt;/h4>&lt;p>A code-validate-deploy cycle is included in both DevOps and MLOps pipelines. However, the MLOps pipeline also includes data and model stages that are necessary to create and train a machine learning model (see diagram below). As a result, MLOps has a few differences from traditional DevOps for each component of the workflow.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/mlops_6_23/MLOps-DevOps.webp"
width="896"
height="432"
srcset="https://zinef.github.io/p/mlops_6_23/MLOps-DevOps_hu_34477051f9523420.webp 480w, https://zinef.github.io/p/mlops_6_23/MLOps-DevOps_hu_371d600d4e29773a.webp 1024w"
loading="lazy"
alt="ML &amp;#43; Dev &amp;#43; Ops"
class="gallery-image"
data-flex-grow="207"
data-flex-basis="497px"
>&lt;/p>
&lt;p>&amp;ldquo;data&amp;rdquo; and &amp;ldquo;model&amp;rdquo; here represent, in most cases, the data labeling, data transformation or feature engineering and algorithm selection process which we can call the experiment phase.&lt;/p>
&lt;p>&lt;strong>Data labeling&lt;/strong> is the process of adding the target to a chunk of data records and the model will use this as a training set. In the case of a supervised ML model this type of data is critical.&lt;/p>
&lt;p>&lt;strong>Data transformation or feature engineering&lt;/strong> is also an important step to preprocess and prepare the most suitable structure for the ML model in order to produce good results.&lt;/p>
&lt;p>And &lt;strong>selecting algorithm process&lt;/strong> depends on the nature of the prediction problem at hand.&lt;/p>
&lt;p>The &amp;ldquo;Dev&amp;rdquo; and &amp;ldquo;Ops&amp;rdquo; parts are mostly the same at a high level.&lt;/p>
&lt;p>The experimentation phase is unique to the data science lifecycle, which reflects how data scientists traditionally do their work. This differs from the way code developers do their work. The following diagram illustrates this life cycle in more detail.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/mlops_6_23/tdsp-lifecycle.png"
width="1150"
height="858"
srcset="https://zinef.github.io/p/mlops_6_23/tdsp-lifecycle_hu_e45b6dd94d3d1536.png 480w, https://zinef.github.io/p/mlops_6_23/tdsp-lifecycle_hu_ae699e5994cea53b.png 1024w"
loading="lazy"
alt="Data Science Life Cycle"
class="gallery-image"
data-flex-grow="134"
data-flex-basis="321px"
>&lt;/p>
&lt;h4 id="development-and-cicd">Development and CI/CD
&lt;/h4>&lt;p>The &amp;ldquo;development&amp;rdquo; takes two different meanings in each concept. In DevOps, by development we mean the code that creates an application or interface of some sort. The code is then wrapped up in an executable (artifact) that is deployed and validated against a series of tests. This cycle is ideally automated and continues until you have a final product. However, in MLOps the code is building/training a ML model. The output artifact here is a serialized file that can have data fed into it and produce inferences. The validation would be checking how well the trained model does against test data. Similarly, this is a cycle that continues until the model performs at a certain threshold.&lt;/p>
&lt;h4 id="version-control">Version control
&lt;/h4>&lt;p>In a DevOps pipeline, version control is usually limited to tracking changes to code and artifacts. There are more things to track in an MLOps pipeline.&lt;/p>
&lt;p>As mentioned before, the code in MLOps is building/training the ML model and it is an iterative cycle of experimenting. Each experimental run&amp;rsquo;s components and metrics must be tracked in order to appropriately recreate it afterwards for auditing reasons. The data set utilized in training (train/test split), the model construction code, and the model artifact are among these components. The hyper-parameters and model performance are among the metrics (e.g., error rate).&lt;/p>
&lt;p>When compared to standard software systems, this may appear to be a lot of information to keep track of. Fortunately, we have model registry tools (&lt;a class="link" href="https://www.phdata.io/blog/what-is-a-model-registry/" target="_blank" rel="noopener"
>https://www.phdata.io/blog/what-is-a-model-registry/&lt;/a>) as a tailor-made solution for versioning ML models.&lt;/p>
&lt;h4 id="monitoring">Monitoring
&lt;/h4>&lt;p>Model drift is an additional component to monitor in MLOps, in addition to the application itself. Because data is continuously changing, your model must as well. Models trained on older data may or may not perform well on new data, particularly if the data is seasonal.&lt;/p>
&lt;p>In order to keep your model up to date, it will need to be re-trained regularly (&lt;a class="link" href="https://www.phdata.io/blog/when-to-retrain-machine-learning-models/" target="_blank" rel="noopener"
>https://www.phdata.io/blog/when-to-retrain-machine-learning-models/&lt;/a>) to gain consistent value from it.&lt;/p>
&lt;p>&lt;img src="https://zinef.github.io/p/mlops_6_23/monitoring.webp"
width="1024"
height="602"
srcset="https://zinef.github.io/p/mlops_6_23/monitoring_hu_769743d0a89db269.webp 480w, https://zinef.github.io/p/mlops_6_23/monitoring_hu_477412dc59565eaf.webp 1024w"
loading="lazy"
alt="Monitoring"
class="gallery-image"
data-flex-grow="170"
data-flex-basis="408px"
>&lt;/p>
&lt;h2 id="why-mlops">Why MLOps?
&lt;/h2>&lt;p>The importance of MLOps cannot be overstated. By establishing more efficient processes, utilizing data analytics for decision-making, and enhancing customer experience, machine learning helps individuals and enterprises deploy solutions that uncover previously untapped streams of revenue, save time, and decrease cost.&lt;/p>
&lt;p>These objectives are difficult to achieve without a solid foundation to operate within. MLOps automates model creation and deployment, resulting in faster time to market and lower operating expenses. It assists managers and developers in making more strategic and agile decisions.&lt;/p>
&lt;p>MLOps provides as a road map for individuals, small teams, and even enterprises to fulfill their objectives regardless of their restrictions, such as sensitive data, limited resources, or a limited budget.&lt;/p>
&lt;p>Because MLOps are not set in stone, you may choose the size of your map. You may try out various options and keep only what works for you.&lt;/p>
&lt;h2 id="best-practices">Best Practices
&lt;/h2>&lt;p>In this section, we will see the best practices for different parts of an ML project, Team, DATA, Metrics&amp;amp;KPI, Model, Code and the Deployment.&lt;/p>
&lt;h3 id="team">Team
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>Use A collaborative Development Platform:&lt;/strong> by making consistent use of a collaborative dev platform teams can work together more effectively. All this is possible because dev platforms provides easy access to data, code, information and other tools. One other interesting thing is that platforms help teams to work together asynchronously or remotely. Collaborative development environments include GitHub, GitLab, BitBucket, and Azure DevOps Server.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Work Against a Shared Backlog:&lt;/strong> intent to avoid misunderstanding on the content, priority and status of tasks because an actively maintained backlog enables coordination of tasks within the team and with external stakeholders. It also helps in planning ahead and performing retrospective evaluations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Communicate and Collaborate with others:&lt;/strong> The system that your team develops is meant to integrate with other systems within the context of a wider organization. this requires communication, alignment, and collaboration with others outside the team.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="data">Data
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>Use Sanity Checks for All External Data Sources:&lt;/strong> Avoid invalid or incomplete data being processed because data errors is crucial for model quality&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Write Reusable Scripts for Data Cleaning and Merging:&lt;/strong> Avoid untidy data wrangling scripts, reuse code and increase reproducibility.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Ensure Data Labelling is Performed in a Strictly Controlled Process:&lt;/strong> Avoid invalid or incomplete labels, Controlling the data labelling process ensures label quality &amp;ndash; an important quality driver for supervised learning algorithms.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Make Data Sets Available on Shared Infrastructure (private or public):&lt;/strong> Avoid data duplication, data bottlenecks, or unnecessary transfer of large data sets.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="metrics--kpi">Metrics &amp;amp; KPI
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>At first, track multiple metrics, not necessarily the best one:&lt;/strong> You want to make money, make your users happy, and make the world a better place. There are tons of metrics that you care about, and you should measure them all. However, early in the machine learning process, you will notice them all going up, even those that you do not directly optimize.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Establish Responsible AI Values:&lt;/strong> Explicitly align all stakeholders on the ethical values and constraints of your machine learning application&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Enforce Fairness and Privacy:&lt;/strong> Avoid irresponsible use of machine learning and decisions with negative societal impact.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="model">Model
&lt;/h3>&lt;p>The first thing to do with the model is to get it simple, interpretable and get the infrastructure right, that what makes debugging easier&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Share a Clearly Defined Training Objective within the Team:&lt;/strong> Avoid misunderstandings between multi-disciplinary team members. In a multi-disciplinary team, members with different backgrounds may misinterpret training objectives. Therefore, it is important to clearly communicate the objectives within the team.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Capture the Training Objective in a Metric that is Easy to Measure and Understand:&lt;/strong> Ensure the machine learning objective is easy to measure and it is a good proxy for the true objective.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Test all Feature Extraction Code&lt;/strong>: Avoid bugs in the feature extraction code to ensure the non presence of errors and bugs in the whole process.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Enable Parallel Training Experiments:&lt;/strong> Avoid deadlocks during experimentation. Machine learning relies heavily on empirical processes. In order to allow fast experimentation and avoid deadlocks, it is recommended to think upfront of experiment parallelisation.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Continuously Measure Model Quality and Performance&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Use Versioning for Data, Model, Configurations and Training Scripts&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="code">Code
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>Run Automated Regression Tests:&lt;/strong> Avoid the introduction of bugs in code. When making changes, new defects can easily be introduced in existing code. A suite of automated regression tests helps to spot such defects as early as possible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Use Continuous Integration&lt;/strong>: Catch any code integration problems as early as possible. Code changes and additions may introduce problems into the software system as a whole. This can be detected by running an automated build script each time that code is committed to the versioning repository.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Assure Application Security&lt;/strong>: to Prevent attackers from stealing or corrupting data, or from disrupting the availability of an application. Security incidents can lead to public data leaks, financial losses, or disrupt the availability of an application.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="deployment">Deployment
&lt;/h3>&lt;ul>
&lt;li>
&lt;p>&lt;strong>Automate Model Deployment:&lt;/strong> Increase the ability to deploy models on demand, which increases availability and scalability. Deploying and orchestrating different components of an application can be a tedious task. Instead of manually packaging and delivering models, and in order to avoid manual interventions or errors, one can automate this task.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Enable Shadow Deployment:&lt;/strong> Test a model&amp;rsquo;s behaviour on production data, without any impact on the service it provides. Before pushing a model into production, it is wise to test its quality and performance on data from production. In order to facilitate this task, one can deploy multiple models to &amp;lsquo;shadow&amp;rsquo; each other.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Continuously Monitor the Behaviour of Deployed Models:&lt;/strong> To Avoid unintended behaviour in production models. Once a model is promoted to production, the team has to understand how it performs.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Log Production Predictions with the Model&amp;rsquo;s Version and Input Data:&lt;/strong> To Enhance debugging, enable traceability, reproducibility, compliance and incident management. Tracing decisions back to the input data and the model&amp;rsquo;s version can be difficult. It is therefore recommended to log production predictions together with the model&amp;rsquo;s version and input data.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="machine-learning-operations-maturity-model">Machine Learning Operations Maturity Model
&lt;/h2>&lt;p>The purpose of this maturity model is to help clarify the principles and practices of Machine Learning Operations (MLOps). The maturity model shows continuous improvement in the creation and operation of a production-level machine learning application environment. You can use it as a metric to establish the incremental requirements needed to measure the maturity of a machine learning production environment and its associated processes.&lt;/p>
&lt;p>As with most maturity models, the MLOps maturity model qualitatively assesses personas/culture, processes/structures, and objects/technologies. As the maturity level increases, the probability increases as incidents or errors lead to quality improvements in the development and production processes.&lt;/p>
&lt;p>The MLOps maturity model encompasses five levels of technical capability:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Level&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Description&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Key points&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Technology&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>0&lt;/td>
&lt;td>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model#level-0-no-mlops" target="_blank" rel="noopener"
>No MLOps&lt;/a>&lt;/td>
&lt;td>- Difficulty in managing the full life cycle of machine learning models&lt;br>- Teams are heterogeneous and releases are painful&lt;br>- Most systems exist as &amp;ldquo;black boxes&amp;rdquo;, little feedback during/after deployment&lt;/td>
&lt;td>- Manual builds and deployments&lt;br>- Manual model and application testing&lt;br>- No centralized monitoring of model performance&lt;br>- Model training is manual&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model#level-1-devops-no-mlops" target="_blank" rel="noopener"
>DevOps but no MLOps&lt;/a>&lt;/td>
&lt;td>- Production releases are less painful than non-MLOps, but rely on the data team for each new model&lt;br>- Feedback on model performance in production is always limited&lt;br>- Difficult trace/reproduction results&lt;/td>
&lt;td>- Automated Builds&lt;br>- Automated tests for the application code&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model#level-2-automated-training" target="_blank" rel="noopener"
>Automated Training&lt;/a>&lt;/td>
&lt;td>- The training environment is fully managed and traceable&lt;br>- Easy to reproduce model&lt;br>- Versions are manual, but low friction&lt;/td>
&lt;td>- Automated model learning&lt;br>- Centralized tracking of training model performance&lt;br>- Model management&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model#level-3-automated-model-deployment" target="_blank" rel="noopener"
>Automated Model Deployment&lt;/a>&lt;/td>
&lt;td>- Low-friction, automatic releases&lt;br>- Full traceability from deployment to source data&lt;br>- Entire environment managed: training &amp;gt; testing &amp;gt; production&lt;/td>
&lt;td>- Integrated A/B testing of model performance for deployment&lt;br>- Automated testing for all code&lt;br>- Centralized tracking of training model performance&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model#level-4-full-mlops-automated-retraining" target="_blank" rel="noopener"
>Full MLOps Automated Operations&lt;/a>&lt;/td>
&lt;td>- Complete automated and easily monitored system&lt;br>- Production systems provide information on how to improve and, in some cases, automatically, new models&lt;br>- Approach of a system without dead time&lt;/td>
&lt;td>- Automated training and testing of models&lt;br>- Feedback, centralized metrics from a deployed model&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>For more information on each level, please click on the link in the description.&lt;/p>
&lt;h2 id="types-of-mlops-solutions">Types of MLOps solutions
&lt;/h2>&lt;p>Depending on your needs, the choice of the MLOps solution can be made on the following two types:&lt;/p>
&lt;ol>
&lt;li>End to end MLOps solution&lt;/li>
&lt;li>Custom build MLOps solution&lt;/li>
&lt;/ol>
&lt;h3 id="end-to-end-mlops-solution">End to end MLOps solution
&lt;/h3>&lt;p>These type of solution provides data scientists the ability to build, train and deploy ML models quickly, the solutions are fully managed services. And the best solutions for this type could be:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Amazon:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Amazon sagemaker:&lt;/strong> Amazon SageMaker is an ML service that enables data scientists and engineers, as well as MLOps engineers and business analysts, to create, train, and deploy ML models for any use case, regardless of their level of ML expertise.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Google Cloud MLOps suite:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Dataflow:&lt;/strong> Fast, unified and cost-effective serverless batch and stream data processing.&lt;/li>
&lt;li>&lt;strong>Kubeflow pipelines:&lt;/strong> Kubeflow Pipelines is a platform for building and deploying portable, scalable machine learning (ML) workflows based on Docker containers.&lt;/li>
&lt;li>&lt;strong>Google Kubernetes Engine:&lt;/strong> A simple way to automatically deploy, scale and manage Kubernetes.&lt;/li>
&lt;li>&lt;strong>TFX:&lt;/strong> TensorFlow Extended (TFX) is an end-to-end platform for deploying production ML pipelines&lt;/li>
&lt;li>&lt;strong>Vertex AI Workbench&lt;/strong>: A single development environment for the entire data science workflow.&lt;/li>
&lt;li>&lt;strong>ML kit:&lt;/strong> Machine learning for mobile developers, ML Kit brings Google&amp;rsquo;s machine learning expertise to mobile developers in a powerful and easy-to-use package. Make your iOS and Android apps more engaging, personalized, and helpful with solutions that are optimized to run on device.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Microsoft Azure MLOps suite:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Azure Machine Learning:&lt;/strong> Empower data scientists and developers to build, deploy, and manage high-quality models faster and with confidence. Accelerate time to value with industry-leading machine learning operations (MLOps), open-source interoperability, and integrated tools. Innovate on a secure, trusted platform designed for responsible AI applications in machine learning.&lt;/li>
&lt;li>&lt;strong>Azure Kubernetes Service (AKS):&lt;/strong> Azure Kubernetes Service (AKS) offers the quickest way to start developing and deploying cloud-native apps, with built-in code-to-cloud pipelines and guardrails. Get unified management and governance for on-premises, edge, and multicloud Kubernetes clusters. Interoperate with Azure security, identity, cost management, and migration services.&lt;/li>
&lt;li>&lt;strong>Azure Pipelines:&lt;/strong> Continuously build, test, and deploy to any platform and cloud.&lt;/li>
&lt;li>&lt;strong>Azure Monitor:&lt;/strong> Azure Monitor helps you maximize the availability and performance of your applications and services.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="custom-built-mlops-solution">Custom built MLOps solution
&lt;/h3>&lt;p>For making the pipeline robust, the custom-built solution is the best for you, this approach can help you avoid a single point of failure and makes your pipeline easier to audit, debug and more customizable. There are many tools available for this approach:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Project jupyter:&lt;/strong> Free software, open standards, and web services for interactive computing across all programming languages&lt;/li>
&lt;li>&lt;strong>Nbdev:&lt;/strong> a library that allows you to develop a python library in Jupyter Notebooks, putting all your code, tests and documentation in one place.&lt;/li>
&lt;li>&lt;strong>Airflow:&lt;/strong> Airflow is a platform created to programmatically author, schedule and monitor workflows.&lt;/li>
&lt;li>&lt;strong>Kubeflow:&lt;/strong> The Machine Learning Toolkit for Kubernetes.&lt;/li>
&lt;li>&lt;strong>MLflow:&lt;/strong> An open source platform for the machine learning lifecycle&lt;/li>
&lt;li>&lt;strong>Neptune:&lt;/strong> Neptune is an ML metadata store that was built for research and production teams that run many experiments.&lt;/li>
&lt;li>&lt;strong>Optuna:&lt;/strong> An open source hyperparameter optimization framework to automate hyperparameter search&lt;/li>
&lt;li>&lt;strong>Cortex:&lt;/strong> Deploy, manage, and scale machine learning models in production.&lt;/li>
&lt;/ul>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>Now that you have in mind all the definitions and best practices of MLOps, you can chose one of the two solutions and go for it. Even better I invite you to consult my next article where I will present a solution and implementation of a MLOps pipeline.&lt;/p>
&lt;h2 id="references">References
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://se-ml.github.io/practices/" target="_blank" rel="noopener"
>https://se-ml.github.io/practices/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://developers.google.com/machine-learning/guides/rules-of-ml" target="_blank" rel="noopener"
>https://developers.google.com/machine-learning/guides/rules-of-ml&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/mlops-maturity-model&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/aml-decision-tree" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-ie/azure/architecture/example-scenario/mlops/aml-decision-tree&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-ie/azure/architecture/data-guide/azure-dataops-architecture-design" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-ie/azure/architecture/data-guide/azure-dataops-architecture-design&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/fr-fr/azure/architecture/example-scenario/mlops/mlops-technical-paper" target="_blank" rel="noopener"
>https://docs.microsoft.com/fr-fr/azure/architecture/example-scenario/mlops/mlops-technical-paper&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://neptune.ai/blog/category/mlops" target="_blank" rel="noopener"
>https://neptune.ai/blog/category/mlops&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.phdata.io/blog/when-to-retrain-machine-learning-models/" target="_blank" rel="noopener"
>https://www.phdata.io/blog/when-to-retrain-machine-learning-models/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.phdata.io/blog/what-is-a-model-registry/" target="_blank" rel="noopener"
>https://www.phdata.io/blog/what-is-a-model-registry/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=uTEL8Ff1Zvk" target="_blank" rel="noopener"
>https://www.youtube.com/watch?v=uTEL8Ff1Zvk&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops" target="_blank" rel="noopener"
>https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#devops_versus_mlops&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.datasciencecentral.com/mlops-vs-devops-the-similarities-and-differences/" target="_blank" rel="noopener"
>https://www.datasciencecentral.com/mlops-vs-devops-the-similarities-and-differences/&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://towardsdatascience.com/building-a-devops-pipeline-for-machine-learning-and-ai-evaluating-sagemaker-cf7fdd3632e7" target="_blank" rel="noopener"
>https://towardsdatascience.com/building-a-devops-pipeline-for-machine-learning-and-ai-evaluating-sagemaker-cf7fdd3632e7&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Unleash Limitless Possibilities: Harness the Power of Generative AI to Meet Market Demands and Delight Your Clients</title><link>https://zinef.github.io/p/genai_6_22/</link><pubDate>Sun, 04 Jun 2023 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/genai_6_22/</guid><description>&lt;img src="https://zinef.github.io/p/genai_6_22/cover.jpg" alt="Featured image of post Unleash Limitless Possibilities: Harness the Power of Generative AI to Meet Market Demands and Delight Your Clients" />&lt;p>Have you ever struggled with the daunting task of code migration? Whether itâ€™s moving from SAS to Python or Snowflake or BigQuery, C# to Python, PL/SQL to Snow SQL, or migrating ETL processes from Informatica to Snowflake, the challenges can be overwhelming. Not to mention the complexities involved in converting reports from Tableau to Power BI or Qlik to Power BI. However, with the groundbreaking capabilities of generative AI, these seemingly Herculean tasks can now be accomplished effortlessly and affordably. Say goodbye to traditional, time-consuming workflows and embrace the transformative power of generative AI in your migration endeavors.&lt;/p>
&lt;p>Recently, I embarked on a fascinating journey into the realm of Generative AI, and the discoveries Iâ€™ve made are too exciting not to share. In this article, I have curated a collection of powerful use cases that demonstrate the remarkable potential of Generative AI to revolutionize the data science field. So, fasten your seatbelts as we explore the possibilities that lie ahead.&lt;/p>
&lt;h2 id="understanding-generative-ai">Understanding Generative AI
&lt;/h2>&lt;p>Before we claw into the captivating world of Generative AI, letâ€™s take a moment to familiarize ourselves with its environment. Generative AI refers to a branch of artificial intelligence that focuses on creating models able of producing new and original content. These models can induce realistic images, vids, music, and text that nearly resembles human creations.&lt;/p>
&lt;p>Generative AI can be divided into two subtypes, models that calculate the density (explicit density) and models that can only sample the density (implicit density), and these are further divided into subtypes, at the bottom of the tree we retrieve mostly these models :&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Autoencoders (VAE):&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>Autoencoders serve as a fundamental building block of Generative AI. They are neural networks designed to learn efficient representations of data by encoding and decoding it. One compelling use case of autoencoders is their ability to facilitate fraud detection and anomaly detection.&lt;/p>
&lt;ol start="2">
&lt;li>&lt;strong>Generative Adversarial Networks (GANs):&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>GANs employ a two-part network comprising a generator and a discriminator, which work together to produce realistic outputs. GANs have found remarkable success in various domains, such as image synthesis, video generation, and even designing new products. For instance, GANs can aid in the creation of highly realistic images for marketing and advertising purposes or assist architects in envisioning realistic renderings of buildings that are yet to be constructed.&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>Diffusion Models:&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>Diffusion models are powerful generative AI techniques that excel in generating high-quality, realistic samples. These models learn the underlying probability distribution of a dataset and can then generate new samples that resemble the original data. They have shown great potential in fields such as image synthesis, medical anomaly detection, and data augmentation.&lt;/p>
&lt;ol start="4">
&lt;li>&lt;strong>Large Language Models (LLMs):&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>Among the various subtypes of Generative AI models, Large Language Models (LLMs) have been trending in recent years. These models are trained on vast amounts of text data and can generate coherent and contextually relevant text responses. With the advancements in LLMs, numerous applications have emerged, including language translation, chatbots, content generation, and even code completion. In this article, we will primarily focus on the intriguing use cases of LLMs.&lt;/p>
&lt;p>&lt;img src="https://cdn-images-1.medium.com/max/3840/1*ePhP1tOGcL2VkMzcHZigtg.png"
loading="lazy"
alt="Image by LifeArchitect.ai/gpt-3"
>&lt;em>Image by &lt;a class="link" href="http://LifeArchitect.ai/gpt-3" target="_blank" rel="noopener"
>LifeArchitect.ai/gpt-3&lt;/a>&lt;/em>&lt;/p>
&lt;p>&lt;img src="https://cdn-images-1.medium.com/max/3840/1*TE9hCCFjMVT0EywFwn3MHw.png"
loading="lazy"
alt="Image by LifeArchitect.ai/gpt-4"
>&lt;em>Image by &lt;a class="link" href="http://LifeArchitect.ai/gpt-4" target="_blank" rel="noopener"
>LifeArchitect.ai/gpt-4&lt;/a>&lt;/em>&lt;/p>
&lt;h2 id="deep-dive-into-captivating-use-cases">Deep Dive into Captivating Use Cases
&lt;/h2>&lt;p>Now that we have laid the foundation, letâ€™s dive into the captivating use cases that have caught my attention. These innovative applications of Generative AI are not only transforming industries but also enhancing the capabilities of data scientists, paving the way for groundbreaking advancements in their respective fields.&lt;/p>
&lt;h3 id="cognitive-search-using-embeddings">Cognitive Search using Embeddings
&lt;/h3>&lt;p>In today&amp;rsquo;s data-driven world, the ability to extract relevant information quickly and efficiently is paramount. Traditional keyword-based search engines often fall short when it comes to understanding the context and nuances of user queries. However, with the advent of Generative AI, specifically the utilization of embeddings, a revolutionary approach to search has emerged.&lt;/p>
&lt;p>Embeddings, in the context of Generative AI, refer to vector representations that capture the semantic meaning of words, phrases, or documents. By leveraging advanced techniques like GPT or BERT (Bidirectional Encoder Representations from Transformers), these embeddings enable machines to comprehend the underlying meaning and relationships within textual data.&lt;/p>
&lt;p>Cognitive search powered by embeddings offers significant advantages over traditional search methods. It can understand the intent behind user queries, consider the context, and provide more accurate and relevant search results.&lt;/p>
&lt;p>Here&amp;rsquo;s an example to illustrate its potential: Imagine you are working in a large organization that generates vast amounts of data. You need to find specific documents related to a particular project. Instead of relying solely on keyword matching, cognitive search with embeddings can understand the project&amp;rsquo;s context and return documents that are semantically relevant. It can even suggest related documents that might be useful, even if they don&amp;rsquo;t contain the exact search terms.&lt;/p>
&lt;p>Furthermore, embeddings allow for semantic similarity searches. This means that you can search for documents that are conceptually similar to a given document, even if the keywords or phrases differ. For instance, if you have a document describing a marketing campaign, cognitive search can identify other documents discussing similar marketing strategies or related topics.&lt;/p>
&lt;p>By harnessing the power of embeddings in cognitive search, organizations can enhance their knowledge discovery processes, improve search accuracy, and save valuable time and resources. Whether it&amp;rsquo;s within enterprise knowledge management systems, customer support portals, or e-commerce platforms, cognitive search using embeddings empowers users to explore and retrieve information more effectively.&lt;/p>
&lt;p>This use case illustrates how Generative AI, particularly leveraging embeddings, revolutionizes the way we interact with and extract insights from textual data. The potential for cognitive search is vast, and as the technology advances, we can expect even more sophisticated applications that redefine how we access and make sense of information.&lt;/p>
&lt;h3 id="anything-from-anything--code-migration-and-platform-conversion">Anything from Anything : Code Migration and Platform Conversion
&lt;/h3>&lt;p>Generative AI has proven to be a game-changer when it comes to code migration and platform conversion. Traditional approaches to these tasks often involve significant time, effort, and potential risks. However, with the power of Generative AI, these processes can be streamlined, making them faster, more efficient, and cost-effective.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Code migration :&lt;/strong> Migrating code from one language or platform to another can be a complex and time-consuming endeavor. Generative AI techniques, such as LLMs, can aid in this process by learning the underlying structure and patterns of the source code and generating equivalent code in the desired language or platform.
For example, letâ€™s consider the migration of code from SAS to Python. Instead of manually rewriting the entire codebase, Generative AI models can be trained on existing SAS code to learn the syntax, logic, and functionality. The models can then generate equivalent code in Python, reducing the effort and potential errors involved in the migration process. Similarly, migrating code from languages like C# to Python or PL/SQL to Snow SQL can be facilitated through Generative AI. By leveraging the power of AI, organizations can minimize the challenges associated with code migration, accelerate the transition process, and capitalize on the benefits of new technologies and platforms.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Platform Conversion :&lt;/strong> Platform conversion, such as migrating ETL processes from one platform to another, is another area where Generative AI shines. Take, for example, the migration from Informatica to Snowflake. Generative AI techniques can analyze the existing ETL workflows, understand the data transformations, and generate equivalent workflows in Snowflakeâ€™s ETL. This enables a seamless transition between platforms, ensuring data continuity and minimizing disruption. Moreover, Generative AI can assist in converting reports from one visualization platform to another. For instance, converting reports from Tableau to Power BI or Qlik to Power BI can be a laborious task. However, by leveraging the power of Generative AI, the models can learn the visualization structures, data mappings, and formatting styles of the source reports. They can then generate equivalent reports in the desired target platform, significantly reducing the time and effort required for manual conversion.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Additionally, Generative AI can be used in the automation of test cases. By training models on existing codebases and test suites, they can generate unit test cases for programming languages like Java or Python. This automation streamlines the testing process, enhances code quality, and frees up valuable time for data scientists to focus on higher-level tasks.&lt;/p>
&lt;p>Generative AIâ€™s ability to streamline code migration, platform conversion, report conversion, and test automation is transformative. It empowers organizations to adapt to new technologies, optimize workflows, and unlock efficiencies that were previously challenging to achieve. With Generative AI as a driving force, the data science field is witnessing a paradigm shift in how these tasks are approached and executed.&lt;/p>
&lt;h3 id="business-analytics-service-enablement">Business Analytics Service Enablement
&lt;/h3>&lt;p>Generative AI has the potential to transform business analytics services by enabling intuitive and user-friendly solutions. Imagine a scenario where clients can effortlessly extract insights from vast amounts of data, just like requesting information from a virtual assistant. Generative AI makes this a reality by empowering business analytics platforms, such as Power BI or Tableau, with advanced capabilities.&lt;/p>
&lt;p>Clients often express the desire for a streamlined and automated analytics experience. They envision a solution where they can simply ask for specific data insights and receive visually appealing graphs or charts without the need for complex queries or manual data manipulation.&lt;/p>
&lt;p>Generative AI brings this vision to life. By leveraging natural language processing and machine learning techniques, analytics platforms can understand and interpret user requests in plain language. Clients can say, â€œGive me the sales of this product in this region for this monthâ€ and the system will intelligently retrieve the relevant data, perform the necessary calculations, and present the requested insights in an intuitive and visually appealing manner.&lt;/p>
&lt;p>The integration of Generative AI into business analytics services enables a self-service analytics experience that empowers users at all levels of an organization. Executives, business analysts, and data scientists alike can effortlessly explore and visualize complex data sets, extract valuable insights, and make data-driven decisions without the need for extensive technical knowledge or assistance.&lt;/p>
&lt;p>This use case illustrates the transformative power of Generative AI in revolutionizing business analytics services. It not only enhances the accessibility of data but also empowers organizations to unlock the full potential of their data assets. By simplifying the analytics process, organizations can make faster, data-driven decisions, uncover hidden trends and patterns, and gain a competitive edge in their respective industries.&lt;/p>
&lt;p>As Generative AI continues to advance, we can expect even more sophisticated analytics service enablement solutions. The ability to seamlessly interact with data and extract actionable insights will become increasingly intuitive, making data-driven decision-making a seamless part of everyday business operations.&lt;/p>
&lt;h3 id="medical-nlp-using-biogpt">Medical NLP using BioGPT
&lt;/h3>&lt;p>Medical professionals deal with a vast amount of unstructured textual data, including patient records, clinical notes, research papers, and more. Extracting valuable insights from this data can be a time-consuming and labor-intensive task. However, Generative AI, specifically Natural Language Processing (NLP) models like BioGPT, has emerged as a powerful tool to revolutionize medical data analysis and decision-making.&lt;/p>
&lt;p>BioGPT, a specialized variant of Generative Pre-trained Transformer (GPT) models, is specifically trained on medical literature and healthcare-related text. This pre-training equips it with a deep understanding of medical concepts, terminology, and context. By leveraging BioGPT, medical professionals and researchers can unlock valuable insights from vast amounts of unstructured medical data.&lt;/p>
&lt;p>One key application of BioGPT is in clinical decision support. Medical professionals can input patient symptoms, medical history, and test results into the system, and BioGPT can analyze the data to provide recommendations for diagnosis, treatment options, and potential risk factors. This assists healthcare providers in making more informed decisions and improving patient outcomes.&lt;/p>
&lt;p>Furthermore, BioGPT can aid in biomedical research and literature review. By processing and analyzing a vast array of research papers, clinical trials, and scientific articles, BioGPT can identify relevant studies, extract key findings, and provide summaries or insights on specific medical topics. This significantly accelerates the research process, enabling scientists and clinicians to stay up-to-date with the latest advancements and make evidence-based decisions.&lt;/p>
&lt;p>Another application of BioGPT in medical NLP is in coding and structuring medical records. Medical coding is a crucial process that ensures accurate reimbursement, clinical documentation, and data analysis. BioGPT can automatically extract relevant information from clinical notes and assign appropriate codes, simplifying the coding process and reducing the risk of errors.&lt;/p>
&lt;p>Moreover, BioGPT can assist in natural language understanding for electronic health records (EHRs). It can analyze and extract important clinical information from free-text EHRs, facilitating data mining and enabling population health analysis. This helps in identifying patterns, predicting disease outcomes, and improving healthcare delivery and planning.&lt;/p>
&lt;p>By harnessing the power of BioGPT and medical NLP, healthcare professionals can streamline data analysis, enhance decision-making, and improve patient care. The combination of advanced language understanding and medical expertise empowers medical practitioners and researchers to extract valuable insights from vast amounts of unstructured medical data, revolutionizing the way healthcare is delivered and improving patient outcomes.&lt;/p>
&lt;p>This use case showcases the tremendous potential of Generative AI, specifically BioGPT, in transforming medical NLP and revolutionizing healthcare data analysis, clinical decision-making, and biomedical research. As the technology continues to advance, we can expect even more sophisticated applications that redefine how medical data is analyzed, interpreted, and utilized in the pursuit of improved healthcare outcomes.&lt;/p>
&lt;h3 id="automated-software-defect-closure">Automated Software Defect Closure
&lt;/h3>&lt;p>Software defects are an inevitable part of the software development process, and closing them in a timely and efficient manner is crucial for delivering high-quality software. Generative AI offers a powerful solution to automate the process of identifying and closing software defects, saving time and resources for development teams.&lt;/p>
&lt;p>Hereâ€™s how automated software defect closure using Generative AI can benefit organizations:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Defect Identification:&lt;/strong> Generative AI models can analyze codebases, logs, and error reports to identify patterns and anomalies that indicate the presence of software defects. By leveraging machine learning algorithms, these models can learn from historical data and develop a deep understanding of different types of defects. This enables them to accurately pinpoint potential issues within the codebase.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Automated Root Cause Analysis:&lt;/strong> Generative AI can assist in performing automated root cause analysis for software defects. By analyzing code changes, dependencies, and system logs, the models can determine the underlying cause of the defect. This information is valuable for developers, as it helps them understand the root cause and address it effectively.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Automated Bug Fix Generation:&lt;/strong> Once a software defect is identified and its root cause determined, Generative AI models can automatically generate potential bug fixes or suggest code changes to resolve the issue. These models leverage their understanding of programming languages, coding best practices, and defect patterns to generate high-quality fixes that adhere to coding standards.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Regression Testing:&lt;/strong> After a bug fix is implemented, Generative AI can assist in performing automated regression testing. The models can generate test cases based on the defect and its fix, ensuring that the issue is resolved and that the fix does not introduce new defects or regressions in the software.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Continuous Learning and Improvement:&lt;/strong> Generative AI models can continuously learn from the feedback provided by developers and testers. This feedback loop helps the models refine their bug detection and fix generation capabilities over time, leading to more accurate and effective defect closure.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Automated software defect closure using Generative AI streamlines the defect resolution process, accelerates bug fixes, and improves software quality. By automating repetitive and time-consuming tasks, development teams can focus on more critical aspects of software development, such as feature implementation and performance optimization.&lt;/p>
&lt;p>This use case demonstrates the transformative potential of Generative AI in automating software defect closure. By leveraging machine learning and automation, organizations can improve software quality, shorten development cycles, and deliver more robust and reliable software products to their customers.&lt;/p>
&lt;h2 id="sum-up">Sum up
&lt;/h2>&lt;p>Generative AI, with its ability to understand, create, and automate, has emerged as a transformative force in the field of data science. Its applications, especially in the realms of Generative AI and Large Language Models (LLMs), have attracted clients and companies across various industries. While the adoption of Generative AI brings immense opportunities and advancements, it is crucial to acknowledge the continued importance of data scientists in harnessing the power of AI.&lt;/p>
&lt;p>Throughout this article, we have explored several captivating use cases that demonstrate the potential of Generative AI to revolutionize various domains. From cognitive search to business analytics service enablement, medical NLP, and automated software defect closure, Generative AI showcases its versatility in driving innovation and efficiency.&lt;/p>
&lt;p>By leveraging Generative AI, organizations can meet the ever-increasing market demand and cater to their clientsâ€™ needs more effectively. The ability to generate meaningful insights from vast amounts of data, automate complex tasks, and improve decision-making processes positions Generative AI as a valuable tool in todayâ€™s data-driven landscape.&lt;/p>
&lt;p>However, it is important to emphasize that Generative AI does not replace the role of data scientists and domain experts. Instead, it enhances their capabilities, enabling them to tackle more complex challenges and leverage AI-powered solutions effectively. Data scientists play a vital role in training, fine-tuning, and validating Generative AI models to ensure accuracy, ethical considerations, and alignment with business objectives.&lt;/p>
&lt;p>As we look to the future, the potential of Generative AI continues to expand. The integration of advanced techniques, such as AutoEncoders, Generative Adversarial Networks (GANs), diffusion models, and Large Language Models (LLMs), opens up new possibilities for innovation and problem-solving.&lt;/p>
&lt;p>In conclusion, Generative AI, with its diverse use cases and transformative capabilities, offers significant value to clients and companies in the data science field. By embracing Generative AI and recognizing the continued importance of data scientists, organizations can unlock the true potential of AI and drive impactful change in their respective industries.&lt;/p>
&lt;p>Remember, Generative AI is a powerful tool, but it is the collaboration between human expertise and AI capabilities that truly propels us towards a future where data-driven insights and solutions are readily accessible, efficient, and impactful.&lt;/p>
&lt;h2 id="references">References
&lt;/h2>&lt;ul>
&lt;li>
&lt;p>&lt;a class="link" href="https://data-science-blog.com/blog/2022/04/19/variational-autoencoders/" target="_blank" rel="noopener"
>Variational Autoencoders&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://data-science-blog.com/blog/2022/03/15/deep-autoregressive-models/" target="_blank" rel="noopener"
>Deep Autoregressive Models&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://data-science-blog.com/blog/2022/02/19/deep-generative-modelling/" target="_blank" rel="noopener"
>Deep Generative Modelling&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://medium.com/analytics-vidhya/an-introduction-to-generative-deep-learning-792e93d1c6d4" target="_blank" rel="noopener"
>An Introduction to Generative Deep Learning&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://arxiv.org/abs/2210.10341" target="_blank" rel="noopener"
>BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://lifearchitect.ai/gpt-3/" target="_blank" rel="noopener"
>The GPT-3 Family: 50+ Models&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://lifearchitect.ai/chatgpt/" target="_blank" rel="noopener"
>GPT-3.5 + ChatGPT: An illustrated overview&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://lifearchitect.ai/gpt-4/" target="_blank" rel="noopener"
>GPT-4&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener"
>The Illustrated Transformer&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://medium.com/@monadsblog/diffusion-models-4dbe58489a2f" target="_blank" rel="noopener"
>Diffusion models&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://arxiv.org/abs/2211.09800" target="_blank" rel="noopener"
>InstructPix2Pix: Learning to Follow Image Editing Instructions&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>How to Effectively Explore and Analyze Multi-Omics Data: Experience Report on Our Web Interface</title><link>https://zinef.github.io/p/multiomics/</link><pubDate>Fri, 05 May 2023 00:00:00 +0000</pubDate><guid>https://zinef.github.io/p/multiomics/</guid><description>&lt;img src="https://zinef.github.io/p/multiomics/dna-closely.jpg" alt="Featured image of post How to Effectively Explore and Analyze Multi-Omics Data: Experience Report on Our Web Interface" />&lt;h2 id="introduction">Introduction
&lt;/h2>&lt;p>In the era of biological big data, multi-omics analysis represents a major challenge for researchers. How can we make sense of these gigantic biological datasets from different layers of cellular information? How can we integrate transcriptomic, proteomic, and metabolomic data to gain a comprehensive view of biological processes?&lt;/p>
&lt;p>These are precisely the questions that my team and I attempted to answer through our project &amp;ldquo;Web Interface: Advanced Analysis of Multi-Omics Data.&amp;rdquo; In this article, I share our experience in creating an interactive web solution that facilitates the complex analysis of these datasets.&lt;/p>
&lt;h2 id="what-are-multi-omics-data">What are Multi-Omics Data?
&lt;/h2>&lt;p>Before diving into the technical details, let&amp;rsquo;s clarify what multi-omics data are. The suffix &amp;ldquo;-omics&amp;rdquo; refers to the comprehensive study of a specific biological system. Thus:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Transcriptomics&lt;/strong> studies the entire set of messenger RNAs (gene expression)&lt;/li>
&lt;li>&lt;strong>Proteomics&lt;/strong> focuses on the complete set of proteins&lt;/li>
&lt;li>&lt;strong>Metabolomics&lt;/strong> analyzes all metabolites (small molecules)&lt;/li>
&lt;li>&lt;strong>Phenomics&lt;/strong> measures the observable characteristics of organisms&lt;/li>
&lt;/ul>
&lt;p>Each of these information layers is represented by large data matrices. Multi-omic analysis aims to integrate these different matrices to understand the complex relationships between the various levels of biological organization.&lt;/p>
&lt;h2 id="the-challenge-wallomics">The Challenge: WallOmics
&lt;/h2>&lt;p>Our project focused on WallOmics data, a dataset from the model plant Arabidopsis thaliana. These data were collected from two different organs (rosettes and stems) of five genetic variants (ecotypes), exposed to two different temperature conditions.&lt;/p>
&lt;p>The main challenge was to explore and analyze this massive data coherently, using matrix factorization approaches and offering an intuitive web interface.&lt;/p>
&lt;h2 id="our-approach-omicsmatrix---the-matrixperience">Our Approach: OmicsMatrix - The Matrixperience
&lt;/h2>&lt;p>Faced with this challenge, we developed &amp;ldquo;OmicsMatrix: The Matrixperience,&amp;rdquo; an interactive web interface based on R Shiny that integrates several advanced analysis methods. Here are the main features we implemented:&lt;/p>
&lt;h3 id="1-intelligent-data-loading-and-preprocessing">1. Intelligent Data Loading and Preprocessing
&lt;/h3>&lt;p>The first step was to enable easy data loading and immediate visualization. Our interface offers the ability to load data from WallOmics Data and automatically prepare it for analysis.&lt;/p>
&lt;p>Our preprocessing pipeline automatically handles:&lt;/p>
&lt;ul>
&lt;li>Detection and treatment of missing values&lt;/li>
&lt;li>Data normalization&lt;/li>
&lt;li>Optional exclusion of irrelevant variables&lt;/li>
&lt;/ul>
&lt;h3 id="2-in-depth-visual-exploration">2. In-depth Visual Exploration
&lt;/h3>&lt;p>Visual exploration is crucial for understanding data structure before applying more complex methods. Our &amp;ldquo;Exploration &amp;amp; PCA&amp;rdquo; panel offers:&lt;/p>
&lt;ul>
&lt;li>A global summary of datasets&lt;/li>
&lt;li>Visualizations of variable distributions&lt;/li>
&lt;li>Interactive correlation matrices&lt;/li>
&lt;li>Principal Component Analysis (PCA) for dimensionality reduction&lt;/li>
&lt;/ul>
&lt;p>PCA proved particularly useful for identifying the most important variables that explain data variance and for visualizing sample separation in a reduced space.&lt;/p>
&lt;h3 id="3-advanced-data-integration-methods">3. Advanced Data Integration Methods
&lt;/h3>&lt;p>Our interface offers four main methods of multi-omic analysis, each with specific advantages:&lt;/p>
&lt;h4 id="regularized-canonical-correlation-analysis-rcca">Regularized Canonical Correlation Analysis (rCCA)
&lt;/h4>&lt;p>This method allows for exploring correlations between two omics datasets. In our experience, rCCA was particularly effective in discovering relationships between transcriptomic and proteomic data.&lt;/p>
&lt;p>One of the challenges encountered with rCCA was the choice of regularization parameters. We implemented two approaches:&lt;/p>
&lt;ul>
&lt;li>Cross-validation (resource-intensive but accurate)&lt;/li>
&lt;li>Shrinkage approach (faster but less optimal)&lt;/li>
&lt;/ul>
&lt;h4 id="partial-least-squares-pls">Partial Least Squares (PLS)
&lt;/h4>&lt;p>The PLS method allowed us to maximize covariance between different data matrices. Its main advantage is its ability to handle highly correlated data, a common characteristic of omics data.&lt;/p>
&lt;p>We also implemented the sparse version (Sparse PLS) which automatically selects the most important variables, thus reducing model complexity.&lt;/p>
&lt;h4 id="pls-da-for-classification">PLS-DA for Classification
&lt;/h4>&lt;p>For classification questions (e.g., distinguishing samples according to their ecotype or growth condition), we used the PLS-DA (Partial Least Squares-Discriminant Analysis) method.&lt;/p>
&lt;p>This method proved particularly useful for identifying biological markers that discriminate between different experimental conditions.&lt;/p>
&lt;h4 id="diablo-for-multiple-integration">DIABLO for Multiple Integration
&lt;/h4>&lt;p>To simultaneously integrate more than two omics datasets, we implemented DIABLO (Data Integration Analysis for Biomarker Discovery using Latent variable approaches for Omics studies).&lt;/p>
&lt;p>DIABLO was the most powerful method in our arsenal, allowing us to discover biomarkers associated with the studied phenotypes by combining information from all available omic layers.&lt;/p>
&lt;h2 id="key-strategies-for-effective-multi-omics-analysis">Key Strategies for Effective Multi-Omics Analysis
&lt;/h2>&lt;p>Based on extensive experience with the OmicsMatrix platform, four critical strategies emerge for successful multi-omics data integration:&lt;/p>
&lt;h3 id="1-rigorous-exploratory-analysis-as-foundation">1. Rigorous Exploratory Analysis as Foundation
&lt;/h3>&lt;p>Comprehensive exploratory analysis must precede any advanced analytical techniques. This foundational step reveals data structure, identifies outliers, and guides subsequent methodological choices. Investing time in thorough exploration consistently yields more interpretable and biologically meaningful final results.&lt;/p>
&lt;h3 id="2-interactive-analysis-workflows">2. Interactive Analysis Workflows
&lt;/h3>&lt;p>Multi-omics analysis demands an iterative approach with continuous parameter refinement. Real-time visualization of these adjustments&amp;rsquo; impact is essential for optimal results. The R Shiny framework provides the necessary reactive environment to support this advanced analytical process.&lt;/p>
&lt;h3 id="3-method-selection-driven-by-biological-questions">3. Method Selection Driven by Biological Questions
&lt;/h3>&lt;p>Each analytical method serves distinct biological objectives. For general data structure understanding, PCA excels; for pairwise dataset relationships, rCCA provides optimal insights; for prediction models, standard PLS offers robust solutions; for classification tasks, PLS-DA delivers superior performance; while comprehensive integration across multiple omics layers requires DIABLO&amp;rsquo;s sophisticated approach.&lt;/p>
&lt;h3 id="4-advanced-visualization-for-biological-interpretation">4. Advanced Visualization for Biological Interpretation
&lt;/h3>&lt;p>Even the most sophisticated analytical results remain ineffective without appropriate visualization techniques. Strategic data visualization transforms complex statistical outputs into interpretable biological insights, facilitating both analysis and communication of findings to diverse stakeholders.&lt;/p>
&lt;h2 id="conclusion">Conclusion
&lt;/h2>&lt;p>The analysis of multi-omics data represents a considerable challenge in bioinformatics, but our experience with OmicsMatrix shows that a well-designed web interface can greatly facilitate this process.&lt;/p>
&lt;p>Our solution has made it possible to effectively analyze WallOmics data and draw relevant biological conclusions about Arabidopsis thaliana&amp;rsquo;s response to different environmental conditions.&lt;/p>
&lt;p>The explosion of high-throughput biological data continues to transform biological research, and tools like OmicsMatrix serve as critical bridges between raw data complexity and actionable biological knowledge.&lt;/p>
&lt;hr>
&lt;p>&lt;em>This article is based on a project carried out in collaboration with Zine-Eddine F, Mohammed I A, and Lounes M, under the supervision of Lazhar L, as part of the MLSD Master&amp;rsquo;s program at UFR BiomÃ©dical.&lt;/em>&lt;/p></description></item><item><title>Archives</title><link>https://zinef.github.io/archives/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://zinef.github.io/archives/</guid><description/></item><item><title>Links</title><link>https://zinef.github.io/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zinef.github.io/links/</guid><description>&lt;!-- To use this feature, add `links` section to frontmatter.
This page's frontmatter:
```yaml
links:
- title: GitHub
description: GitHub is the world's largest software development platform.
website: https://github.com
image: https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
- title: TypeScript
description: TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.
website: https://www.typescriptlang.org
image: ts-logo-128.jpg
```
`image` field accepts both local and external images. --></description></item><item><title>Search</title><link>https://zinef.github.io/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://zinef.github.io/search/</guid><description/></item></channel></rss>